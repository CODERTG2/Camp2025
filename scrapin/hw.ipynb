{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aea27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import urllib.request\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8ff0e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: journal_articles\n"
     ]
    }
   ],
   "source": [
    "keyword = \"machine learning\"\n",
    "num_articles = 10\n",
    "encodingmethod = \"utf-8\"\n",
    "errortype = \"strict\"\n",
    "\n",
    "output_dir = \"journal_articles\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4b4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'machine learning' on arXiv...\n",
      "URL: http://export.arxiv.org/api/query?search_query=all:machine%20learning&start=0&max_results=10\n",
      "Successfully retrieved search results!\n",
      "Successfully retrieved search results!\n"
     ]
    }
   ],
   "source": [
    "encoded_search_term = urllib.parse.quote(keyword, encoding=encodingmethod, errors=errortype)\n",
    "url = f'http://export.arxiv.org/api/query?search_query=all:{encoded_search_term}&start=0&max_results={num_articles}'\n",
    "\n",
    "print(f\"Searching for '{keyword}' on arXiv...\")\n",
    "print(f\"URL: {url}\")\n",
    "\n",
    "try:\n",
    "    url_read = urllib.request.urlopen(url).read().decode(\"utf-8\")\n",
    "    parse_xml = ET.fromstring(url_read)\n",
    "    print(\"Successfully retrieved search results!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32267b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 articles with PDF links\n",
      "1. Lecture Notes: Optimization for Machine Learning...\n",
      "2. An Optimal Control View of Adversarial Machine Learning...\n",
      "3. Minimax deviation strategies for machine learning and recognition with\n",
      "  short l...\n",
      "4. Machine Learning for Clinical Predictive Analytics...\n",
      "5. Towards Modular Machine Learning Solution Development: Benefits and\n",
      "  Trade-offs...\n",
      "6. Introduction to Machine Learning: Class Notes 67577...\n",
      "7. The Tribes of Machine Learning and the Realm of Computer Architecture...\n",
      "8. A Machine Learning Tutorial for Operational Meteorology, Part I:\n",
      "  Traditional M...\n",
      "9. Position Paper: Towards Transparent Machine Learning...\n",
      "10. Understanding Bias in Machine Learning...\n"
     ]
    }
   ],
   "source": [
    "ns = {\"ns\": \"http://www.w3.org/2005/Atom\"}\n",
    "entries = parse_xml.findall('ns:entry', ns)\n",
    "\n",
    "articles_data = []\n",
    "for entry in entries:\n",
    "    link = entry.find('ns:link[@type=\"application/pdf\"]', ns)\n",
    "    if link is not None and \"href\" in link.attrib:\n",
    "        pdf_url = link.attrib['href']\n",
    "        \n",
    "        title = entry.find('ns:title', ns)\n",
    "        title_text = title.text.strip() if title is not None else \"Unknown Title\"\n",
    "        \n",
    "        authors = entry.findall('ns:author/ns:name', ns)\n",
    "        author_names = [author.text for author in authors] if authors else [\"Unknown Author\"]\n",
    "        \n",
    "        published = entry.find('ns:published', ns)\n",
    "        published_date = published.text[:10] if published is not None else \"Unknown Date\"\n",
    "        \n",
    "        summary = entry.find('ns:summary', ns)\n",
    "        summary_text = summary.text.strip() if summary is not None else \"No summary available\"\n",
    "        \n",
    "        metadata = {\n",
    "            'title': title_text,\n",
    "            'authors': author_names,\n",
    "            'published': published_date,\n",
    "            'summary': summary_text\n",
    "        }\n",
    "            \n",
    "        articles_data.append({\n",
    "            'pdf_url': pdf_url,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "\n",
    "print(f\"Found {len(articles_data)} articles with PDF links\")\n",
    "for i, article in enumerate(articles_data):\n",
    "    print(f\"{i+1}. {article['metadata']['title'][:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c371028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1\n",
      "Title: Lecture Notes: Optimization for Machine Learning...\n",
      "saved to: 01_Lecture_Notes_Optimization_for_Machine_Learning.txt\n",
      "saved to: 01_Lecture_Notes_Optimization_for_Machine_Learning.txt\n",
      "Processing article 2\n",
      "Title: An Optimal Control View of Adversarial Machine Learning...\n",
      "Processing article 2\n",
      "Title: An Optimal Control View of Adversarial Machine Learning...\n",
      "saved to: 02_An_Optimal_Control_View_of_Adversarial_Machine_Lea.txt\n",
      "saved to: 02_An_Optimal_Control_View_of_Adversarial_Machine_Lea.txt\n",
      "Processing article 3\n",
      "Title: Minimax deviation strategies for machine learning and recognition with\n",
      "  short l...\n",
      "Processing article 3\n",
      "Title: Minimax deviation strategies for machine learning and recognition with\n",
      "  short l...\n",
      "saved to: 03_Minimax_deviation_strategies_for_machine_learning_.txt\n",
      "saved to: 03_Minimax_deviation_strategies_for_machine_learning_.txt\n",
      "Processing article 4\n",
      "Title: Machine Learning for Clinical Predictive Analytics...\n",
      "saved to: 04_Machine_Learning_for_Clinical_Predictive_Analytics.txt\n",
      "Processing article 4\n",
      "Title: Machine Learning for Clinical Predictive Analytics...\n",
      "saved to: 04_Machine_Learning_for_Clinical_Predictive_Analytics.txt\n",
      "Processing article 5\n",
      "Title: Towards Modular Machine Learning Solution Development: Benefits and\n",
      "  Trade-offs...\n",
      "Processing article 5\n",
      "Title: Towards Modular Machine Learning Solution Development: Benefits and\n",
      "  Trade-offs...\n",
      "saved to: 05_Towards_Modular_Machine_Learning_Solution_Developm.txt\n",
      "saved to: 05_Towards_Modular_Machine_Learning_Solution_Developm.txt\n",
      "Processing article 6\n",
      "Title: Introduction to Machine Learning: Class Notes 67577...\n",
      "Processing article 6\n",
      "Title: Introduction to Machine Learning: Class Notes 67577...\n",
      "saved to: 06_Introduction_to_Machine_Learning_Class_Notes_67577.txt\n",
      "saved to: 06_Introduction_to_Machine_Learning_Class_Notes_67577.txt\n",
      "Processing article 7\n",
      "Title: The Tribes of Machine Learning and the Realm of Computer Architecture...\n",
      "Processing article 7\n",
      "Title: The Tribes of Machine Learning and the Realm of Computer Architecture...\n",
      "saved to: 07_The_Tribes_of_Machine_Learning_and_the_Realm_of_Co.txt\n",
      "saved to: 07_The_Tribes_of_Machine_Learning_and_the_Realm_of_Co.txt\n",
      "Processing article 8\n",
      "Title: A Machine Learning Tutorial for Operational Meteorology, Part I:\n",
      "  Traditional M...\n",
      "Processing article 8\n",
      "Title: A Machine Learning Tutorial for Operational Meteorology, Part I:\n",
      "  Traditional M...\n",
      "saved to: 08_A_Machine_Learning_Tutorial_for_Operational_Meteor.txt\n",
      "saved to: 08_A_Machine_Learning_Tutorial_for_Operational_Meteor.txt\n",
      "Processing article 9\n",
      "Title: Position Paper: Towards Transparent Machine Learning...\n",
      "Processing article 9\n",
      "Title: Position Paper: Towards Transparent Machine Learning...\n",
      "saved to: 09_Position_Paper_Towards_Transparent_Machine_Learnin.txt\n",
      "saved to: 09_Position_Paper_Towards_Transparent_Machine_Learnin.txt\n",
      "Processing article 10\n",
      "Title: Understanding Bias in Machine Learning...\n",
      "Processing article 10\n",
      "Title: Understanding Bias in Machine Learning...\n",
      "saved to: 10_Understanding_Bias_in_Machine_Learning.txt\n",
      "saved to: 10_Understanding_Bias_in_Machine_Learning.txt\n"
     ]
    }
   ],
   "source": [
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "for i, article in enumerate(articles_data):\n",
    "    print(f\"Processing article {i+1}\")\n",
    "    print(f\"Title: {article['metadata']['title'][:80]}...\")\n",
    "        \n",
    "    pdf_response = requests.get(article['pdf_url'], timeout=30)\n",
    "    pdf_response.raise_for_status()\n",
    "        \n",
    "    pdf = PdfReader(BytesIO(pdf_response.content))\n",
    "    pdf_text = \"\"\n",
    "        \n",
    "    for page in pdf.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text.strip():\n",
    "            pdf_text += page_text + \" \"\n",
    "\n",
    "    pdf_text = re.sub(r' {2,}', ' ', pdf_text)\n",
    "    pdf_text = re.sub(r'\\n{3,}', '\\n\\n', pdf_text)\n",
    "    pdf_text = re.sub(r'[\\f\\v\\r]', ' ', pdf_text)\n",
    "    pdf_text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', pdf_text)\n",
    "    pdf_text = re.sub(r'([.!?])\\s*([A-Z])', r'\\1 \\2', pdf_text)   \n",
    "    pdf_text = pdf_text.strip()\n",
    "    \n",
    "    safe_title = re.sub(r'[^\\w\\s-]', '', article['metadata']['title'])\n",
    "    safe_title = re.sub(r'[-\\s]+', '_', safe_title)[:50] \n",
    "    filename = f\"{i+1:02d}_{safe_title}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"JOURNAL ARTICLE #{i+1}\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\\n\")\n",
    "        f.write(f\"Title: {article['metadata']['title']}\\n\")\n",
    "        f.write(f\"Authors: {', '.join(article['metadata']['authors'])}\\n\")\n",
    "        f.write(f\"Published: {article['metadata']['published']}\\n\")\n",
    "        f.write(f\"Source: {article['pdf_url']}\\n\")\n",
    "        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "        f.write(\"ABSTRACT/SUMMARY:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(f\"{article['metadata']['summary']}\\n\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(\"FULL TEXT CONTENT:\\n\")\n",
    "        f.write(\"-\"*80 + \"\\n\")\n",
    "        f.write(pdf_text)\n",
    "    \n",
    "    print(f\"saved to: {filename}\")\n",
    "    successful_downloads += 1\n",
    "    \n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
