{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e93a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "import urllib.error\n",
    "import xml.etree.ElementTree as ET\n",
    "from io import BytesIO\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69575b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"adi\"\n",
    "num_articles = 10\n",
    "encodingmethod = \"utf-8\"\n",
    "errortype = \"strict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c8196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_search_term = urllib.parse.quote(keyword, encoding=encodingmethod, errors=errortype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4b70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'http://export.arxiv.org/api/query?search_query=all:{encoded_search_term}&start=0&max_results={num_articles}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1445247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_read = urllib.request.urlopen(url).read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f30516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_xml = ET.fromstring(url_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3a49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns={\"ns\": \"http://www.w3.org/2005/Atom\"}\n",
    "pdf_urls = [\n",
    "    link.attrib['href']\n",
    "    for entry in parse_xml.findall('ns:entry', ns)\n",
    "    if (link := entry.find('ns:link[@type=\"application/pdf\"]', ns)) is not None\n",
    "    and \"href\" in link.attrib\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3077ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://arxiv.org/pdf/2406.13477v3',\n",
       " 'http://arxiv.org/pdf/2309.00979v1',\n",
       " 'http://arxiv.org/pdf/2310.13661v1',\n",
       " 'http://arxiv.org/pdf/1001.2876v2',\n",
       " 'http://arxiv.org/pdf/1401.5182v2',\n",
       " 'http://arxiv.org/pdf/1406.4251v2',\n",
       " 'http://arxiv.org/pdf/1710.09143v1',\n",
       " 'http://arxiv.org/pdf/2501.05715v1',\n",
       " 'http://arxiv.org/pdf/1912.05412v1',\n",
       " 'http://arxiv.org/pdf/1207.5909v1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bbb4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_request = requests.get(pdf_urls[0], timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45e798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x3a957 for key /Rotate\n",
      "Multiple definitions in dictionary at byte 0x3ad05 for key /Rotate\n"
     ]
    }
   ],
   "source": [
    "pdf = PdfReader(BytesIO(pdf_request.content))\n",
    "pdf_doc = \"\\n\".join(page.extract_text() for page in pdf.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e8f1407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv:2406.13477v3  [math.NA]  23 Jan 2025A unifying framework for ADI-like methods\n",
      "for linear matrix equations and beneﬁcial\n",
      "consequences\n",
      "Jonas Schulze†∗Jens Saak†\n",
      "†Max Planck Institute for Dynamics of Complex Technical Syst ems,\n",
      "Sandtorstr. 1, 39106 Magdeburg, Germany.\n",
      "∗Corresponding author. Email:jschulze@mpi-magdeburg.mpg.de\n",
      "Abstract:\n",
      "We derive the alternating-directions implicit (ADI) method based on a commuting\n",
      "operator split and apply the results in detail to the continuous time a lgebraicLyapunov\n",
      "equation with low-rank constant term and approximate solution, giv ing pointers for\n",
      "the Sylvester case. Previously, it has been mandatory to start th e low-rank ADI for\n",
      "Lyapunov equations (CF-ADI, LR-ADI, G-LR-ADI) or Sylvester e quations (fADI, G-\n",
      "fADI) with an all-zero initial value. Our approach extends the known eﬃcient iteration\n",
      "schemes of low-rank increments and residuals to arbitrary low-ran k initial values for all\n",
      "these methods. We further generalize two properties of the low-r ank Lyapunov ADI\n",
      "to the generic ADI applied to arbitrary linear equations using a commu ting operator\n",
      "split, namely the invariance of iterates under permutations of the s hift parameters, and\n",
      "the eﬃcient handling of complex shift parameters.\n",
      "We investigate the performance of arbitrary initial values using two outer iterations\n",
      "in which the low-rank Lyapunov ADI is typically called. First, we solve an algebraic\n",
      "Riccati equation with the Newton method. Second, we solve a diﬀere ntial Riccati\n",
      "equation with a ﬁrst-order Rosenbrock method. Numerical exper iments conﬁrm that\n",
      "the proposed new initial value of the ADI can lead to a signiﬁcant redu ction in the\n",
      "total number of ADI steps, while also showing a 17% and 8 ×speed-up over the zero\n",
      "initial value for the two equation types, respectively.\n",
      "Keywords: commuting splitting scheme, commuting operator split, low-rank Lya -\n",
      "punov ADI, complex data, non-zero initial value\n",
      "Mathematics subject classiﬁcation: 15A24, 65F10, 65F45, 65F55\n",
      "Novelty statement: We introduce the notion of fully commuting splitting schemes\n",
      "to solve arbitrary linear systems, and derive the ADI method in that context. This\n",
      "allows us to extend the low-rank Lyapunov ADI to non-zero initial va lues. Further-\n",
      "more, we generalize the permutation invariance of ADI iterates to a more general\n",
      "class of algorithms, as well as the existence of a real-valued ADI dou ble-step for\n",
      "complex-conjugated shifts to arbitrary linear systems.\n",
      "1. Intro\n",
      "We consider the numerical solution of the continuous-time algebraic Lyapunov equation (ALE)\n",
      "AX+XAH=−GSGH(1)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 2\n",
      "with large and sparse coeﬃcient matrix A∈Cn×nand a low-rank constant term comprised of\n",
      "the factors G∈Cn×gandS∈Cg×g, whereg≪n. This type of equation arises in, e.g., optimal\n",
      "control and model order reduction. We refer to [ 2,17,42] and the references therein for a more\n",
      "detailed introduction.\n",
      "Given the low rank of the right-hand side of ( 1), the solution can, at least numerically, be well\n",
      "approximated by a low-rank factorization [ 36]. We choose the symmetric indeﬁnite factorization,\n",
      "X≈ZYZH, with talland skinny Z∈Cn×zand Hermitian Y∈Cz×z,z≪n, [14,31]. Forthis kind\n",
      "oflarge-scaleequationswithlow-ranksolutions,themostsuccess fulalgorithmsusedrecentlyarethe\n",
      "Krylovsubspaceprojectionmethod, e.g.,[ 28,29,34,41], aswell asthe ADI method [ 11,14,32,36,46].\n",
      "The latter will be the focus of this paper.\n",
      "The low-rank LyapunovADI had been derived and analyzed using But cher tableaus for ordinary\n",
      "diﬀerential equations (ODEs) [ 19,20], as a Smith method [ 25], as a Krylov method [ 18,47], or by\n",
      "means of Cayley transformations [ 30]. We revise the derivation of the ADI method using the\n",
      "language of linear splitting methods following [ 40, Section 5]. The ADI requires the solution of a\n",
      "linear system at every iteration, which is the dominant part of the ru n-time of the algorithm. Thus\n",
      "far, for every derivation of the low-rank Lyapunov ADI , it has bee n mandatory to use an all zero\n",
      "initial guess, X0= 0, [9–12,14,15,17,31,32,36]. Our motivation is to reduce the number of ADI\n",
      "iterations by extending the method to arbitrary low-rank initial valu es,X0/\\e}atio\\slash= 0. We generalize\n",
      "the iteration scheme of Li and White [ 32] and the residual formulation of Benner, K¨ urschner, and\n",
      "Saak[11] to arbitrarylow-rankinitialvalues forthe low-rankLyapunovADI method atthe expense\n",
      "of an indeﬁnite residual.\n",
      "We investigate the performance of improved initial values using two o uter iterations in which the\n",
      "low-rank Lyapunov ADI is typically called. First, we solve an algebraic R iccati equation (ARE)\n",
      "with the Newton-ADI method; see e.g., Benner, Li, and Penzl [ 14]. Every Newton step requires\n",
      "the solution of one ALE. Especially close to convergence of the Newt on method, the solution of\n",
      "the previous Newton step is expected to be a good candidate to sta rt the ADI with.\n",
      "Second, we solve a diﬀerential Riccati equation (DRE) with a ﬁrst-o rder Rosenbrock method.\n",
      "Each time step requires the solution of an ALE; see e.g., Lang, Mena, and Saak [ 31]. Due to the\n",
      "smoothness of the solution, the solution at the previous time step is a natural candidate to start\n",
      "the next ADI with. Here, we are only concerned with an autonomous equation. We expect the real\n",
      "beneﬁts for the non-autonomous case, where no alternative solv ers exist, and will separately report\n",
      "the results together with similar approaches for BDF methods for t he non-autonomous DRE along\n",
      "the lines of [ 4,5].\n",
      "Throughoutthe paper, /bardbl·/bardbldenotes the Frobenius norm. Re( a+bi) =aand Im(a+bi) =bdenote\n",
      "the real and complex part of a complex scalar (or matrix), respect ively;i=√−1 anda,b∈R. We\n",
      "denote complex conjugation by a+bi=a−bi.Fm×ndenotes the space of m-by-nmatrices with\n",
      "entries in the ﬁeld F. Transposition of a real matrix is denoted by ( ·)T:Rm×n→Rn×m, Hermitian\n",
      "transposition of a complex matrix by ( ·)H:Cm×n→Cn×m.Iqdenotes the identity matrix of\n",
      "sizeq∈N. Whenever we refer to general linear operators, or the matrix dim ensions are evident\n",
      "from the context, we omit the subscript. To simplify notation in many places, we formulate the\n",
      "concatenation of linear operators as multiplication, i.e. A(B(X)) =AB(X) =ABX. Spectrum\n",
      "and spectral radius are denoted by Λ( ·) andρ(·), respectively.\n",
      "Thepaperisstructuredasfollows. In Section 2 , wegeneralizethe notionofsplitting schemesand\n",
      "prove some of the known properties of the low-rank Lyapunov ADI in this more general context.\n",
      "Afterwards, in Section 3 , we derive the ADI for arbitrary linear systems using the framewor k\n",
      "described in Section 2 , while generalizing some of the properties known in the Lyapunov cas e.\n",
      "Section 4 specializes the ADI for Lyapunovequations. In Section 5 we present the two applications\n",
      "mentioned above, as well as some numerical experiments. We conclu de the paper in Section 6 .\n",
      "2. Nonstationary Splitting Schemes\n",
      "Many iterative methods solving Ax=bcan be written in a one-step splitting form\n",
      "Mxk+1=Nxk+b (2)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 3\n",
      "whereM−N=Aand systems Mx=dare “easy”to solve [ 23, Section 11.2.3]. These methods are\n",
      "consistent byconstruction, i.e.everysolutionto Ax=bis aﬁxedpoint ofthe iteration. Conversely,\n",
      "every ﬁxed point xk+1=xkis a solution as well. Assuming that M−1exists, the method converges\n",
      "if the spectral radius ρ(G)<1 forG:=M−1N[23, Theorem 11.2.1]. Gis called iteration matrix\n",
      "of the scheme.\n",
      "The structure above is called ﬁrst normal form of the method [ 26, Chapter 2]. Consistency is\n",
      "equivalent to M−N=A. Thesecond normal form of a consistent linear iteration method reads\n",
      "xk+1=M−1/parenleftbig\n",
      "(M−A)xk+b/parenrightbig\n",
      "=xk−M−1(Axk−b). (3)\n",
      "Furthermore, a splitting method is called nonstationary1if the iteration matrix depends on the\n",
      "iteration, i.e. A=Mk−Nkfork∈N. The normal forms are thus given by\n",
      "Mkxk+1=Nkxk+b, (4a)\n",
      "xk+1=xk−M−1\n",
      "k(Axk−b). (4b)\n",
      "Here, again, we assume that M−1\n",
      "kexists. We will see in the later sections that this is actually not\n",
      "a strong assumption in the context of this article.\n",
      "2.1. Commuting Splitting Schemes\n",
      "We call an operator split A=Mk−Nkand the corresponding iterative method ( 4)commuting if\n",
      "Mk,Nkcommute, i.e.\n",
      "MkNk=NkMk∀k∈N. (5)\n",
      "It is a well known fact that the iteration matrix Gkdetermines the evolution of the error\n",
      "ek:=xk−x∗, whereAx∗=b. Due to the consistency of the method, Mkx∗=Nkx∗+bholds.\n",
      "Subtract this from the ﬁrst normal form ( 4a) to obtain Mkek+1=Nkekor, equivalently,\n",
      "ek+1=Gkek. (6)\n",
      "That the same recursion holds for the residual rk:=Axk−b, is an interesting observation for\n",
      "commuting operator splits.\n",
      "Proposition 2.1 (Residual Recursion[ 40, Proposition5.2]) .LetA=Mk−Nkdeﬁne a commuting\n",
      "nonstationary splitting method (4). Then, the residual rk:=Axk−badheres to\n",
      "rk+1=Gkrk\n",
      "whereGk:=M−1\n",
      "kNkdenotes the iteration matrix.\n",
      "Proof.Due toA=Mk−Nkit isAM−1\n",
      "k=I−NkM−1\n",
      "k. Multiplying ( 5) withM−1\n",
      "kfrom both the\n",
      "left and the right, we ﬁnd that M−1\n",
      "kNk=NkM−1\n",
      "k. Thus, since MkandNkcommute, so do A,\n",
      "M−1\n",
      "k, andNk. Hence, by substituting the ﬁrst normal form ( 4a) into the deﬁnition of the residual,\n",
      "we obtain\n",
      "rk+1=Axk+1−b\n",
      "=A/parenleftbig\n",
      "M−1\n",
      "k(Nkxk+b)/parenrightbig\n",
      "−b\n",
      "=M−1\n",
      "kNkAxk\n",
      "/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "rk+b+AM−1\n",
      "k/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "I−NkM−1\n",
      "kb−b\n",
      "=M−1\n",
      "kNkrk+(M−1\n",
      "kNk−NkM−1\n",
      "k)/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n",
      "0b.\n",
      "This observation allows us to formulate a variant of the second norm al form ( 4b) that iterates\n",
      "the residual rkandincrement vk:=−M−1\n",
      "krkalongside the solution xk. Although Proposition 2.1\n",
      "may be seen as a special case of Hackbusch [ 26, Exercise 2.15], it allows us to give much simpler\n",
      "1Schulze [ 40] called this family of algorithms parametrized splitting schemes.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 4\n",
      "Algorithm 1: Commuting Splitting Scheme\n",
      "Input:operator split A=Mk−NkwithMkNk=NkMkfork∈N, initial guess x0\n",
      "Output: v0,v1,...such that x≈x0+v0+v1+...solvesAx=b\n",
      "1Assemble initial residual r0←Ax0−b\n",
      "2fork∈{0,1,...}do\n",
      "3Compute increment vk←−M−1\n",
      "krk\n",
      "4Update residual rk+1←−Nkvk(alternatively, via rk+1←M−1\n",
      "kNkrk)\n",
      "5ifconverged thenbreak\n",
      "6end\n",
      "7Assemble solution x←x0+v0+v1+...if needed\n",
      "proofs of the known properties of the ADI method applied to Lyapu nov equations. The details are\n",
      "covered in Section 4 .\n",
      "UsingProposition 2.1 together with commutation of M−1\n",
      "kandNk, observed in its proof, as well\n",
      "as the deﬁnition of the increment vk:=−M−1\n",
      "krk, we conclude the following corollary.\n",
      "Corollary 2.2. The residual rk+1only depends on the increment vkleading to the iterate xk+1,\n",
      "that is\n",
      "rk+1=−Nkvk.\n",
      "Combining this with the increment formula once more, gives:\n",
      "Corollary 2.3. The increment vkonly depends on the previous increment vk−1, that is\n",
      "Mkvk=Nk−1vk−1.\n",
      "It may seem that Corollary 2.2 should always give the most eﬃcient way to update the residual.\n",
      "However, Remark 4.3 provides a counter example. At times, Proposition 2.1 in combination with\n",
      "vk:=−M−1\n",
      "krkyields aformulaforthe residual rk+1that is moreeﬃcient to evaluate. In summary,\n",
      "this yields Algorithm 1 .\n",
      "2.2. Fully Commuting Splitting Schemes\n",
      "We call an operatorsplit A=Mk−Nkand the correspondingiterative method ( 4)fully commuting\n",
      "if∀i,j∈Nwe have\n",
      "MiNj=NjMi, M iMj=MjMi,andNiNj=NjNi. (7)\n",
      "In the latter case, the order in which the steps deﬁned by ( M0,N0) to (Mk,Nk) are applied does\n",
      "not matter:\n",
      "Proposition 2.4 (Permutation Invariance [ 40, Proposition 5.1]) .LetA=Mk−Nkbe a fully\n",
      "commuting operator split. Let the initial iterate x0be ﬁxed. Then, the value of xk+1given by the\n",
      "nonstationary splitting method (4)does not depend on the order in which the steps are executed.\n",
      "Proof.Letx∗denote the unique solution to Ax=b. Observe that∀i,j∈N, all iteration matrices\n",
      "Gi:=M−1\n",
      "iNiandGjcommute. Therefore, after applying G0through Gk, the error ek+1=\n",
      "GkGk−1···G0e0doesnotdependontheorderofthesteps, asdoestheiterate xk+1=ek+1+x∗.\n",
      "Proposition 2.4 generalizes Li and White [ 32, Theorem 4.1].\n",
      "3. ADI Method\n",
      "TheADImethodhasoriginallybeendescribedbyPeacemanandRachf ord[35]. Suppose A=H+V\n",
      "for some linear operators HandVand the system to be solved is, again, Ax=bfor given b. Select\n",
      "some parameters αk,βk∈C. Using the shorthand notation\n",
      "H+\n",
      "k:=H+αkI V+\n",
      "k:=V+βkI\n",
      "H−\n",
      "k:=H−βkI V−\n",
      "k:=V−αkI,(8)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 5\n",
      "the ADI method reads\n",
      "H+\n",
      "kxk+1\n",
      "2=b−V−\n",
      "kxk\n",
      "V+\n",
      "kxk+1=b−H−\n",
      "kxk+1\n",
      "2.(9)\n",
      "As a splitting scheme ( 4), the ADI method yields the consistent operator split\n",
      "Mk:= (αk+βk)−1H+\n",
      "kV+\n",
      "k\n",
      "Nk:= (αk+βk)−1H−\n",
      "kV−\n",
      "k.(10)\n",
      "IfHandVcommute, i.e. HV=VH, so do all the shorthands ( 8) as well as the split operators( 10).\n",
      "We summarize these ﬁndings in the following theorem.\n",
      "Theorem 3.1 (Fully Commuting Splitting Scheme) .The ADI method is a fully commuting split-\n",
      "ting scheme (7)assuming that HandVcommute.\n",
      "As we will motivate in the next section ( Remark 4.4 ) the parameters may occur in conjugated\n",
      "pairs. That is, αk+1=αkandβk+1=βk. It is therefore reasonable to look for a more eﬃcient\n",
      "means to handle both steps kandk+ 1 at once, especially as the ADI method preserves real\n",
      "iterates.\n",
      "Theorem 3.2 (Real-valued Double-Step) .LetHandVbe commuting real operators , i.e. they\n",
      "map real elements onto real ones. Suppose that iterate xkand residual rkare real for some ﬁxed\n",
      "k∈N, and that the next ADI parameters fulﬁll\n",
      "αkαk+1, αk+αk+1, βkβk+1, βk+βk+1∈R,\n",
      "for example, αk+1=αkandβk,βk+1∈R. Then, two ADI steps later, the iterate xk+2and\n",
      "residualrk+2are real again.\n",
      "Proof.Weshowconstructivelyhowtocomputeiterate xk+2andresidual rk+2usingrealarithmetic.\n",
      "The residual rk+2=Gk+1Gkrkis real if the operator Gk+1Gkof the combined step is real. Let\n",
      "the scalar\n",
      "σk+1,k:= (αk+1+βk+1)(αk+βk)∈C\\{0}. (11)\n",
      "Recall that H+\n",
      "kandV+\n",
      "k+1commute. We observe that the scaled\n",
      "σk+1,kMk+1Mk= (H+\n",
      "k+1H+\n",
      "k)\n",
      "/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "= (H+αk+1I)(H+αkI)\n",
      "=H2+(αk+αk+1)H+αkαk+1I(V+\n",
      "k+1V+\n",
      "k), (12)\n",
      "is a real operator, as is the scaled σk+1,kNk+1Nkand, consequently, Gk+1Gk. This proves the\n",
      "desired property of the residual rk+2.\n",
      "Moreover, Corollary 2.3 together with the deﬁnition of the increment vk:=−M−1\n",
      "krkimplies\n",
      "thatMk+1vk+1=Nkvk=−NkM−1\n",
      "krk=−M−1\n",
      "kNkrk,asNkandMkcommute. Therefore, by\n",
      "multiplying vkandvk+1withMk+1Mk, we conclude that the increment of the combined step\n",
      "xk+2=xk+vk+vk+1is given by\n",
      "Mk+1Mk(vk+vk+1) =−(Mk+1+Nk)rk. (13)\n",
      "Observe that the scaled\n",
      "σk+1,k(Mk+1+Nk) = (αk+βk)(H+αk+1I)(V+βk+1I)\n",
      "+(αk+1+βk+1)(H−βkI)(V−αkI)(14a)\n",
      "= (αk+αk+1+βk+βk+1)HV\n",
      "+(αkβk+1+βkβk+1−αkαk+1−αkβk+1)H\n",
      "+(αkαk+1+αk+1βk−αk+1βk−βkβk+1)V\n",
      "+/parenleftbig\n",
      "(αk+αk+1)βkβk+1+(βk+βk+1)αkαk+1/parenrightbig\n",
      "I(14b)\n",
      "= (αk+αk+1+βk+βk+1)HV+(βkβk+1−αkαk+1)(H−V)\n",
      "+/parenleftbig\n",
      "(αk+αk+1)βkβk+1+αkαk+1(βk+βk+1)/parenrightbig\n",
      "I(14c)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 6\n",
      "is a real operator as well. Therefore, given that the residual rkis real, equation ( 13) can be solved\n",
      "for the combined increment vk+vk+1using only real arithmetic. This proves the desired property\n",
      "for the iterate xk+2.\n",
      "Theorem 3.2 generalizes [ 12]. It motivates to look for an eﬃcient formulation that handles\n",
      "complex shift parameters when applying the ADI method to anylinear system, in particular, any\n",
      "linear matrix equation.\n",
      "4. Low-rank Lyapunov ADI\n",
      "In this section, we apply the ADI method to an ALE with low-rank right -hand side and solution.\n",
      "Weshowhowtoderiveseverallow-rankvariantsoftheADImethod [8,14,15,31,32], whileextending\n",
      "allthese algorithmsto non-zeroinitial values x0/\\e}atio\\slash= 0. Throughoutthe section, we usethe SVD-type\n",
      "low-rank factorization of, e.g., [ 15], for the iterates xk, increments vk, residuals rk, and right-hand\n",
      "sidesb.\n",
      "Consider the ALE\n",
      "L(X) :=GSGH+AX+XAH= 0 (15)\n",
      "for square matrices A,X∈Cn×n,G∈Cn×g, andS∈Cg×g. We assume that λi+λj/\\e}atio\\slash= 0 for\n",
      "any two eigenvalues λi,λj∈CofA; that is, equation ( 15) permits a unique solution; see, e.g., [ 1,\n",
      "Corollary 1.1.4] for a system-theoretical perspective, or [ 27] for a linear algebraic perspective. We\n",
      "are aiming to approximate the solution as X≈ZYZH, where Z∈Cn×z,Y∈Cz×z. If the\n",
      "constant term has a low rank g≪n, we can expect the solution to have a low numerical rank as\n",
      "well [3,24,37,39,45].\n",
      "In terms of the previous section, H(U) :=AUandV(U) :=UAH, which obviously commute,\n",
      "(HV)(U) =AUAH= (VH)(U). For generalized equations, the situation is not as simple.\n",
      "Remark 4.1 (Generalized Matrix Equations) .For a generalized Lyapunov equation\n",
      "AXET+EXAT=−W\n",
      "we can, in general, not expect AandEto commute. For non-singular E, however, it is still\n",
      "possible to symbolically transform the above equation into its simpler equivalent (15), in which case\n",
      "the restriction of Theorem 3.1 becomes trivial. Then, however, it is mandatory to rephrase the\n",
      "actual steps of the ADI individually along the lines of Saak [ 38, Section 5.2], to avoid inversion\n",
      "ofE.\n",
      "For this reason, we continue deriving the low-rank ADI for standar d equations ( 15). The overall\n",
      "ADI operator split reads\n",
      "Mk(U) = (αk+βk)−1(A+αkI)U(A+βkI)H,\n",
      "Nk(U) = (αk+βk)−1(A−βkI)U(A−αkI)H,(16)\n",
      "which is symmetry preserving if we choose βk:=αk. We further require that −αkis not an\n",
      "eigenvalue of A, such that Mkis invertible. As long as the initial guess X0=Z0Y0ZH\n",
      "0is symmetric,\n",
      "the same will hold for the residuals and increments. The residual of a low-rank factorization can\n",
      "itself be expressed as a low-rank factorization, L(ZYZH) =RTRH,where\n",
      "R=/bracketleftbigG Z AZ/bracketrightbig\n",
      "∈Cn×(g+2z)\n",
      "T=\n",
      "S· ·\n",
      "· ·Y\n",
      "·Y·\n",
      "∈C(g+2z)×(g+2z)(17)\n",
      "have rank at most g+2z≪n. In particular, L(0) =GSGHis a rank- gfactorization, given both\n",
      "GandShave full rank.\n",
      "Lemma 4.2 (Consistent Lyapunov Residual) .There exists a factorization of the Lyapunov ADI\n",
      "residualrk=RkTRH\n",
      "kthat is consistent with the initial residual r0=R0TRH\n",
      "0. That is, the inner\n",
      "factorTdoes not depend on the iteration k∈N.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 7\n",
      "Proof.Without loss of generality, suppose rk=RkTkRH\n",
      "kfork∈N. Substitute the split opera-\n",
      "tors (16) into the residual update of Proposition 2.1 ,Mkrk+1=Nkrk, to obtain\n",
      "(A+αkI)Rk+1Tk+1RH\n",
      "k+1(A+αkI)H= (A−αkI)RkTkRH\n",
      "k(A−αkI)H. (18)\n",
      "By choosing the outer factor according to\n",
      "(A+αkI)Rk+1= (A−αkI)Rk, (19)\n",
      "the inner factor does not need to change; that is, Tk+1=Tk=T.\n",
      "Moreover, we may utilize the deﬁnition of the increment vkfor a more eﬃcient evaluation of\n",
      "the residual factors. The formulation Mk(vk) =−rkdirectly reveals a factorization vk=VkˆYkVH\n",
      "k,\n",
      "which we will now explain. Using the Lyapunov operator split ( 16),\n",
      "(2Reαk)−1(A+αkI)VkˆYkVH\n",
      "k(A+αkI)H=−RkTRH\n",
      "k, (20)\n",
      "which is fulﬁlled for\n",
      "(A+αkI)Vk=Rk,ˆYk=−2Re(αk)T. (21)\n",
      "Therefore, by simple algebraic reformulations of the Lyapunov res idual formula ( 19), we observe\n",
      "Rk+1= (A+αkI)−1(A−αkI)Rk\n",
      "=Rk−2Re(αk)(A+αkI)−1Rk\n",
      "=Rk−2Re(αk)Vk.(22)\n",
      "This relation has previously been derived by Benner, K¨ urschner, a nd Saak [ 11] in the low-rank\n",
      "ADI context as well as Wolf and Panzer [ 47] interpreting the iteration as an implicit, in general\n",
      "oblique, Krylov subspace projection method.\n",
      "Remark 4.3 (Eﬃcient Residual Update) .Had we instead used Corollary 2.2 ,rk+1=−Nkvk, to\n",
      "derive the residual factors, we would have obtained\n",
      "Rk+1= (A−αkI)Vk, (23)\n",
      "which can at best be evaluated with near-linear complexity i fAis sparse. In contrast, formula (22)\n",
      "can be evaluated with linear complexity irrespective of A.\n",
      "Remark 4.4 (Shifts and Eigenvalues) .Ideally, the residual rk+1=Rk+1TRH\n",
      "k+1= 0should vanish.\n",
      "By formula (23), that means AVk=αkVk, which is only possible if αkis an eigenvalue of A, andVk\n",
      "spans (a subspace of) the corresponding eigenspace. Relaxi ng this to a Ritz-Galerkin-type condition,\n",
      "multiplying with VH\n",
      "kfrom the left, and thus turning the eigenvalues into Ritz-va lues, motivates why\n",
      "both Penzl’s heuristic shifts [ 36] and the self-generating projection shifts [ 13] usually perform very\n",
      "well. The fact that, in the case of a real matrix, eigenvalues occur in conjugated pairs motivates\n",
      "Theorem 3.2 .\n",
      "The problem with the so-called V(u)-shifts [13], however, is that αkandVkare not chosen at the\n",
      "same time. Instead, Vkis determined by αkand the previous residual factor Rkvia formula (21),\n",
      "whileαkis determined by some previous increments ˜V:= [Vk−ℓ−1,Vk−ℓ−2,...,V k−ℓ−u]viaαk∈\n",
      "Λ(˜VHA˜V,˜VHE˜V),whereℓ∈Ndenotes the number of steps taken since the last shift comput ation.\n",
      "Recall that the solution Xhas a low (numerical) rank. Therefore, we do not expect the sp ace\n",
      "spanned by the increment Vkto deviate much from ˜V, such that the oﬀset ℓdoes not matter much.\n",
      "The arguments above lead to the algorithm described by Lang, Mena , and Saak [ 31, Algo-\n",
      "rithm 3.1]. Recall, however, that our derivation does not require a ze ro matrix initial guess X0= 0.\n",
      "Unfortunately, using the construction from the proof of Theorem 3.2 we obtain the algorithm\n",
      "described by Benner, Li, and Penzl [ 14, Algorithm 4], and not the more eﬃcient formulation by\n",
      "Benner, K¨ urschner, and Saak [ 12, Algorithm 3].\n",
      "However, the formulations by Lang, Mena, and Saak [ 31] to handle complex shifts straight-\n",
      "forwardly apply to the case of a non-zero initial value in the ADI itera tion. We summarize the\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 8\n",
      "Algorithm 2: Frobenius norm of a low-rank factorization\n",
      "Input:matrices Z∈Cn×zandY∈Cz×z,z≪n\n",
      "Output: ρ=/bardblZYZH/bardbl\n",
      "1Compute Rfrom the economy-size QR factorization Z=QR, i.e.R∈Cz×z\n",
      "2ρ←/bardblRYRH/bardbl\n",
      "Algorithm 3: Low-rank Lyapunov ADI\n",
      "Input:system matrices A,E,G, andS, initial value X0=Z0Y0ZH\n",
      "0,\n",
      "parameters{α0,α1,...}\n",
      "Output: V0,V1,...∈Cn×mandT∈Cm×mcomprising ZandYsuch that X≈ZYZH\n",
      "solves the Lyapunov equation AXEH+EXAH=−GSGH\n",
      "1Assemble initial residual factors:\n",
      "R0←/bracketleftbigG EZ 0AZ0/bracketrightbig\n",
      ", T←\n",
      "S· ·\n",
      "· ·Y0\n",
      "·Y0·\n",
      "\n",
      "2k←0\n",
      "3repeat\n",
      "4ifαkis realthen // single step\n",
      "5 Compute increment factor Vk←(A+αkE)−1Rk\n",
      "6 Update residual factor Rk+1←Rk−2Re(αk)EVk\n",
      "7 k←k+1\n",
      "8else // double-step; αk+1=αkmust hold\n",
      "9 Solve complex-valued system ˆVk←(A+αkE)−1Rk\n",
      "10 Compute increment factors:\n",
      "δk←Re(αk)/Im(αk)\n",
      "Vk←√\n",
      "2/parenleftbig\n",
      "Re(ˆVk)+δkIm(ˆVk)/parenrightbig\n",
      "Vk+1←√2δk+2Im(ˆVk)\n",
      "11 Update residual factor Rk+2←Rk−2√\n",
      "2Re(αk)EVk\n",
      "12 k←k+2\n",
      "13end\n",
      "14untilconverged\n",
      "15Assemble solution factors, if needed:\n",
      "Z←/bracketleftbigZ0V0V1.../bracketrightbig\n",
      "Y←blockdiag/parenleftbig\n",
      "Y0,−2Re(α0)T,−2Re(α1)T, .../parenrightbig\n",
      "low-rank Lyapunov ADI as derived by Proposition 2.1 andRemark 4.1 inAlgorithm 3 . For the\n",
      "convergence criterion in line 14we use\n",
      "/bardblrk/bardbl=/bardblRkTRH\n",
      "k/bardbl≤/braceleftBigg\n",
      "abstolADI\n",
      "reltolADI/bardblGSGH/bardbl= reltol ADI/bardblb/bardbl,(24)\n",
      "depending on whether abstol ADI∈Ror reltol ADI∈Rhas been provided. Either way, we evaluate\n",
      "all Frobenius norms of low-rank factorizations using Algorithm 2 [14,36]. Note that accumulation\n",
      "ofQcan be avoided [ 14], e.g., using Householder QR or (shifted) Cholesky QR; see [ 23].\n",
      "Remark 4.5 (Other formulations of the ADI iteration for Linear Matrix Equation s).Applying\n",
      "Corollary 2.3 ,Mkvk=Nk−1vk−1, to the Lyapunov operator split (16)for Cholesky-type low-\n",
      "rank iterates Xk=ZkZH\n",
      "kand data W=BBHyields the CF-ADI algorithm described by Li and\n",
      "White [32]. Applying the same reformulation as in equation (22)leads to the LR-ADI as described\n",
      "by Benner, Li, and Penzl [ 14]. Recall, however, that our derivation does not require a ze ro matrix\n",
      "initial guess; that is, X0= 0orZ0= [].\n",
      "Applying Corollary 2.3 ,Mkvk=Nk−1vk−1, to the Sylvester equation AX−XB=Wleads\n",
      "to the fADI method described by Benner, Li, and Truhar [ 15]. Specializing Algorithm 1 to the\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 9\n",
      "Sylvester equation leads to the G-fADI described by Benner a nd K¨ urschner [ 8], which iterates the\n",
      "residual alongside.\n",
      "Remark 4.6 (Alternative Derivation) .Observe that L(X0+ˆV) = 0is a Lyapunov equation in\n",
      "the increment ˆV,\n",
      "L(X0+ˆV) =RTRH+AˆV+ˆVAH= 0.\n",
      "whereRandTare the Lyapunov residual factors (17). Applying the ADI to solve for ˆVand\n",
      "starting with rank-zero ˆV0= 0, is equivalent to applying the ADI to solve for X0+ˆVand starting\n",
      "withX0.\n",
      "5. Applications and Numerical Experiments\n",
      "In this section, we recall two iterative algorithms that solve an ALE a t every step. If we solve these\n",
      "ALEs with another iterative method, like the ADI, it is natural to use the previous outer iterate\n",
      "as the initial guess for the inner method.\n",
      "Morespeciﬁcally, let Xℓdenotethe outeriterates, ℓ∈N, and let Xℓ+1,kdenote the inner iterates,\n",
      "k∈N, whose ﬁnal iterate will become Xℓ+1. Then, it is natural to choose Xℓ+1,0=Xℓinstead of,\n",
      "e.g.,Xℓ+1,0= 0.\n",
      "All computationsin this sectionhavebeen performed on anIntel Xe on Silver4110. We evaluated\n",
      "the following shift strategies:\n",
      "•heur(10,10,10): Penzl’s heur( l0,k+,k−) strategy, which ﬁrst computes eigenvalues based on\n",
      "k+Arnoldi iterations of E−1Aandk−Arnoldi iterations of A−1E, and selects l0of them\n",
      "based on a greedy heuristic [ 36]. If more than l0shifts are needed, we repeat these l0-many\n",
      "selected shifts cyclically.\n",
      "•heur(20,30,30)\n",
      "•proj(2,heur): One of the self-generating projection strategies, which is calledV(u)-shifts\n",
      "in [30, Section 5.3.1]. In our case u= 2, to properly account for a potential ADI double-step.\n",
      "Here, we order these Ritz values based on Penzl’s heuristic.\n",
      "•proj(2,dec): The same V(2)-shifts ordered by decreasing real part. In the case of real- valued\n",
      "shifts, the shifts are equivalently ordered by increasing magnitude , since all such shifts must\n",
      "have a negative real part.\n",
      "•proj(2,inc): The same V(2)-shifts ordered by increasing real part.\n",
      "In general, we expect fewer ADI iterations for larger l0∈Nin the case of heur( l0,k+,k−) shifts,\n",
      "and even fewer iterations for the proj shifts. In that notion, we c all shifts to be better or worse\n",
      "than others.\n",
      "Remark 5.1 (Accuracy of Ritz Values) .It is critical that Penzl’s shifts are computed precisely\n",
      "as described in [ 36], since it is by no means clear that the largest or smallest ei genvalues and cor-\n",
      "responding eigenspaces are the most relevant for the soluti on process. For example, using the k+\n",
      "largest and k−smallest eigenvalues of E−1Aas computed by ArnoldiMethod.jl [ 44] (version 0.2.0)\n",
      "compared to Penzl’s procedure, limiting to only a few Arnold i steps and Ritz values, being com-\n",
      "parably rough approximations of the eigenvalues, leads to 5to10×more ADI iterations. These\n",
      "values are too accurate and ignore relevant eigenspaces sti ll covered by Penzl’s Ritz values. When\n",
      "computing highly accurate eigenvalues, choosing those fro m the dominant poles of the underlying\n",
      "dynamical system, for which the ALE is solved, can be beneﬁci al [38, Section 8.1].\n",
      "Remark 5.2 (OrderofShifts andEigenvalues) .Benner, K¨ urschner, and Saak require that complex\n",
      "conjugated pairs remain adjacent, but do otherwise not spec ify the order in which the V-shifts shall\n",
      "be used [ 13]. As we will see later, the ADI can be quite susceptible to the order of the shifts.\n",
      "Given that, for example, MATLAB’s eigdoes not guarantee a particular order but appears to keep\n",
      "complex conjugated pairs adjacent, while Julia’s eigvals sorts the eigenvalues lexicographically\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 10\n",
      "by real and imaginary parts (similar to the proj(2,inc)shifts), the unaware user may observe\n",
      "drastically diﬀerent convergence behaviors. Try, for exam ple,\n",
      "A= blockdiag/parenleftbigg/bracketleftbigg\n",
      "−3 4\n",
      "−4 3/bracketrightbigg\n",
      ",/bracketleftbigg\n",
      "−4 3\n",
      "−3 4/bracketrightbigg\n",
      ",/bracketleftbigg\n",
      "−3 2\n",
      "−2 3/bracketrightbigg\n",
      ",−5,−3/parenrightbigg\n",
      ".\n",
      "Julia’s order is problematic insofar as complex conjugated pairs are not adjacent, which is required\n",
      "for an ADI double-step. Therefore, when sorting the eigenva lues based on their real part, we also\n",
      "sort by the absolute value of their imaginary parts, in order to keep complex conjugated pairs\n",
      "adjacent. Penzl’s heuristic ensures this property by itsel f.\n",
      "We conclude this section’s introduction by mentioning some implementa tion details. The ex-\n",
      "amples to follow will all lead to real-valued system matrices. We theref ore expect a real-valued\n",
      "solution ZYZT∈Rn×nas well; see Theorem 3.2 . All Frobenius norms of ZYZTfactorizations\n",
      "are evaluated using Algorithm 2 . The systems arising in the ADI increment formulas ( 21), lines4\n",
      "and8ofAlgorithm 3 , may have a low-rank updated structure,\n",
      "A+αkE/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "sparse+UVT\n",
      "/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "low-rank∈Cn×n, (25)\n",
      "whereUandVare real and have few columns. The only complex contribution will be f rom the\n",
      "ADI shifts αk∈C. In this case, we apply the Sherman-Morrison-Woodbury formula; e.g., [23,\n",
      "Section 2.1.4].2\n",
      "We perform a column compression of any factored representation ZYZT∈Rn×n, as described\n",
      "by Lang, Mena, and Saak [ 31], every 10 low-rank additions/subtractions,\n",
      "Z1Y1ZT\n",
      "1±Z2Y2ZT\n",
      "2=/bracketleftbigZ1Z2/bracketrightbig/bracketleftbiggY1\n",
      "±Y2/bracketrightbigg\n",
      "/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n",
      "Y∈Rk×k/bracketleftbigZ1Z2/bracketrightbigT, (26)\n",
      "or once the inner dimension reaches 50% of the outer dimension; k≥0.5n. The eigenvalues of the\n",
      "resulting inner matrix ˆYare truncated such that\n",
      "Λ(ˆY) =/braceleftbig\n",
      "λ∈Λ(Y) :|λ|≥max{1,ρ(Y)}·k·umach/bracerightbig\n",
      ", (27)\n",
      "where Λ(·) andρ(·) denote the spectrum and spectral radius, respectively. We fur ther compress\n",
      "every low-rank Lyapunov right-hand side Wbefore solving AX+XAT=−W, unless mentioned\n",
      "otherwise.\n",
      "5.1. Algebraic Riccati Equation\n",
      "We apply the Newton-Kleinman method to the algebraic Riccati equat ion (ARE)\n",
      "R(X) :=CTC+ATXE+ETXA−ETXBBTXE= 0, (28)\n",
      "with matrices\n",
      "E,A∈Rn×n, B∈Rn×m, C∈Rq×n, (29)\n",
      "andm,q≪n. Due to the low rank of CTCandBBT, we can expect the solution to have a low\n",
      "numerical rank; see Benner and Bujanovi´ c [ 6]. Hence, we factorize the Newton iterates according\n",
      "toXℓ=ZℓYℓZT\n",
      "ℓwithZℓ∈Rn×zℓandYℓ∈Rzℓ×zℓ. Adapted from Benner, Li, and Penzl [ 14], the\n",
      "ℓth step ( ℓ∈N) of the Kleinman formulation reads\n",
      "0 =Lℓ(Xℓ+1) :=GℓSℓGT\n",
      "ℓ+AT\n",
      "ℓXℓ+1E+ETXℓ+1Aℓ, (30)\n",
      "2For more general examples, the structure of the low-rank par t in (25) may be UDVTfor some D/\\egatio\\slash=I. In that\n",
      "case, the center terms Sℓof the Lyapunov equations to come (equations ( 30) and (38)) need to be modiﬁed\n",
      "slightly, and the Sherman-Morrison-Woodbury formula requ ires a term D. For ease of notation, we stick to the\n",
      "simpler case ( 25).\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 11\n",
      "where\n",
      "Aℓ=A−BBTXℓE∈Rn×n,\n",
      "Gℓ=/bracketleftbig\n",
      "CTETXℓB/bracketrightbig\n",
      "∈Rn×(q+m),\n",
      "Sℓ=I∈R(q+m)×(q+m).(31)\n",
      "Note that Aℓhas the structure of a sparse matrix updated by a low-rank matrix product, using\n",
      "U=BandVT=BTXℓE. LetXℓ+1,kfork∈Ndenotethe ADI iteratesduringthe solutionof ( 30).\n",
      "Note further that although the value of Gℓdepends on the current iterate Xℓ, the dimensions of Gℓ\n",
      "areconstant.3Therefore,theADIstartedwith Xℓ+1,0= 0willhaveanadvantage,asitsLyapunov\n",
      "residuals Lℓ(Xℓ+1,k) will always have (at most) q+mcolumns, which determines the cost to solve\n",
      "the linear systems deﬁning the ADI increments. The new ADI with Xℓ+1,0=Xℓ=ZℓYℓZT\n",
      "ℓ\n",
      "having inner dimension zℓwill lead to Lyapunov residuals having up to ( q+m) + 2zℓcolumns;\n",
      "see formula ( 17). We do not yet use the common EHZℓblock in the outer low-rank factor, which\n",
      "would allow factorization having inner dimension q+2zℓ< q+m+2zℓand, thus, slightly reduced\n",
      "compression times.\n",
      "The Riccati residual of a low-rank factorization can naively be writt en in a low-rank form as\n",
      "R(ZℓYℓZT\n",
      "ℓ) =RTRT,where\n",
      "R=/bracketleftbig\n",
      "CTATZℓETZℓ/bracketrightbig\n",
      "∈Rn×(q+2zℓ)\n",
      "T=\n",
      "I· ·\n",
      "· · Yℓ\n",
      "·Yℓ−YℓZT\n",
      "ℓBBTZℓYℓ\n",
      "∈R(q+2zℓ)×(q+2zℓ),(32)\n",
      "compare, e.g., [ 14]. We consider the Newton method to have converged once\n",
      "/bardblR(Xℓ+1)/bardbl<reltolNewton/bardblCTC/bardbl (33)\n",
      "for some user-provided reltol Newton. Next, we describe how to conﬁgure the ADI convergence\n",
      "criterion ( 24) based on three diﬀerent variations of the Newton method. First, for the classical\n",
      "Newton method we use\n",
      "reltolADI= reltol Newton/10. (34a)\n",
      "Second, to speed up the early Newton iterations, we use an inexact Newton method with variable\n",
      "forcing term η∈Rdescribed by Dembo, Eisenstat, and Steihaug [ 22], resulting in\n",
      "abstolADI=η/bardblR(Xℓ)/bardbl. (34b)\n",
      "Third, to speed up the later Newton steps with already small /bardblR(Xℓ)/bardbl, we switch back to the\n",
      "classicalNewtonmethodiftheinexactbound( 34b)becomessmallerthantheclassicalbound( 34a).\n",
      "This “hybrid” Newton method results in\n",
      "abstol ADI= max/braceleftbig\n",
      "η/bardblR(Xℓ)/bardbl,1\n",
      "10reltolNewton/bardblLℓ(0)/bardbl/bracerightbig\n",
      ". (34c)\n",
      "Furthermore, to keep the potential overshootof the Riccati re sidual in control, which refers to an\n",
      "increasingRiccati residual, as usually observed in the ﬁrst Newton it erations, we employ an Armijo\n",
      "linesearch.4AsdescribedbyBenneretal.[ 7], thelinesearchisappliedif /bardblR(ˆXℓ+1)/bardbl>0.9/bardblR(Xℓ)/bardbl,\n",
      "whereˆXℓ+1denotes the solution to the classical Newton step ( 30).\n",
      "Example 5.3. We apply the procedure described above to the Steel Proﬁle be nchmark [ 16,33],\n",
      "which is based on a semi-discretized heat transfer problem. The corresponding matrices (36)have\n",
      "m= 7inputs,q= 6outputs, and are available for several sizes n. For this work, we focus on the\n",
      "conﬁguration n= 5177. However, the input matrix B= 1000ˆBis a scalar multiple of the original\n",
      "Steel Proﬁle matrix ˆB. The factor 1000controls the relative weighting of control and output costs of\n",
      "3Except for an outer initial value X0= 0, which would allow G0=CTwhich has only qcolumns. For simplicity,\n",
      "we did not implement this, nor do we perform a column-compres sion on the right-hand side.\n",
      "4Our implementation is rather naive in that it does not utiliz e the connection between R(X) andLℓ(X) described\n",
      "in [7, Equation (5.2b)]. However, the overall runtime cost of the line search was negligible (less than 1% of the\n",
      "total runtime).\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 12\n",
      "the corresponding linear quadratic regulator problem. In t his setting it corresponds to a factor 10−6\n",
      "on the control costs, decreasing the regularity of the optim al control problem and, thus, making the\n",
      "ARE harder to solve. Consequently, we observe a higher overs hoot of the Riccati residual norm\n",
      "and more Newton steps. We use the quadratic forcing term η= min{0.1,0.9/bardblR(Xℓ)/bardbl}also used\n",
      "by Benner et al. [ 7]. The Newton tolerance is reltolNewton= 10−10.\n",
      "Table 1gives an overview on the number of ADI and Newton iterations requir ed to solve the\n",
      "ARE (28) arising from Example 5.3 , as well as the accumulated run-time of the ZYZTcolumns\n",
      "compression, tcompress, the time to compute the ADI shifts, tshifts, the time of all the linear solvesof\n",
      "Algorithm 3 ,tsolve, as well as the total run-time of the Newton method. The ADI shift strategies\n",
      "are described at the beginning of this section. We observe that ena bling the line search reduces the\n",
      "number of Newton steps, but only mildly reduces the number of ADI s teps, as mentioned in [ 7].\n",
      "Switching to the inexact or hybrid Newton method has a much larger e ﬀect on the number of ADI\n",
      "steps. Replacing the zero initial ADI value by the previous Newton ite rate further reduces the\n",
      "number of ADI steps by up to 4 ×(516 vs 121). This reduction is strongest for the simplest shift\n",
      "strategy, heur(10 ,10,10). The old ADI outperforms the new one in most conﬁgurations of the\n",
      "Newton method, and its run-time is dominated by tsolve. Only for the inexact and hybrid Newton\n",
      "method with heur(10 ,10,10) shifts, our new ADI has a slight run-time advantage. In these c ases,\n",
      "however, tcompressis the most expensive part of the algorithm, indicating further pote ntial for\n",
      "improvements especially for our new ADI, when only bad shifts are kn own.\n",
      "We observe a certain dependence of the new ADI on the order of th e (projection) shifts. By\n",
      "merely changing from the decreasing to the increasing order (see Remark 5.2 ), the number of ADI\n",
      "iterations more than doubles (595 vs 1302). The large number of AD I iterations for proj(2 ,inc)\n",
      "shifts is somewhat reasonable; refer to Appendix A for an explanation. Meanwhile, the old ADI\n",
      "seems barely aﬀected. However, most conﬁgurations using inexac t or hybrid Newton with projec-\n",
      "tion shifts did not converge. Only the new ADI with proj(2 ,dec) shifts made the inexact methods\n",
      "without line search converge. Further inspection is needed to unde rstand this phenomenon.\n",
      "In terms of the number of ADI iterations, the optimal conﬁguratio n for the old ADI is the\n",
      "hybrid Newton method with line search and heur(20 ,30,30) shifts. The new ADI performed best\n",
      "for the same Newton method and the simpler heur(10 ,10,10) shifts. Our present implementation\n",
      "of the heuristic shift strategy is not yet optimized, which skews the total run-time of the old ADI\n",
      "in favor of the simpler shifts. Thus, currently, we observe a 3 ×reduction in the number of ADI\n",
      "steps (348 vs 121), and a modest speedup of about 17% in favor of the new ADI (18 .3s vs 15.7s)\n",
      "when compared to the old ADI with the lowest number of ADI steps an d run-time, respectively.\n",
      "However, for any conﬁguration other than the inexact Newton me thods with the simplest shift\n",
      "strategy, the old ADI outperforms our new ADI. More research is needed in how to select the\n",
      "optimal Newton conﬁguration and ADI shifts.\n",
      "Fortheremainderofthissubsection, wefocusonconﬁgurationwit h thelowestrun-timeforeither\n",
      "ADI, namely the hybrid Newton method with line search using heur(10 ,10,10) shifts. Figure 1\n",
      "shows that the new ADI requires much fewer iterations per Newton step; as expected. We further\n",
      "see that the number of old ADI iterations per step does not increas e by much beyond Newton step\n",
      "10 due to the classical bound becoming active in formula ( 34c) for the last three Newton iterations.\n",
      "However, the linear systems to be solved for the ADI increments ( 21) have more columns for the\n",
      "non-zero initial guess; 6 ×as many (78 vs 13) at Newton step 7. Despite this imbalance, the new\n",
      "ADI requires slightly fewer linear system solves overall (6457 vs 670 8). In total, we observe a 6 .0s\n",
      "reduction in tsolveat the cost of a 1 .4s increase in tcompress. In the future, we need to optimize our\n",
      "implementations computing the heuristic shifts as well as the low-ran k column compression.\n",
      "If we plot the Riccati and Lyapunov residuals for all inner ADI iterat ions directly one after the\n",
      "other, we obtain Figure 2. When starting the next Newton step’s ADI with the current Newto n\n",
      "iterate,Xℓ+1,0=Xℓ, the corresponding Riccati residual obviously does not change. M eanwhile,\n",
      "whenstartingwith thezeromatrix, Xℓ+1,0= 0, thenormalizedRiccatiresidualwilljump backto1.\n",
      "Both eﬀects are clearly visible in Figure 2; for the curve of the old ADI it marks the start of every\n",
      "Newton iteration. The curve of the new ADI jumps back to 1 only due to the single line search\n",
      "applied after the ﬁrst Newton step. Furthermore, we observe a s tagnation of the naive Riccati\n",
      "residual ( 32) during the ADI towards the end of every Newton step irrespectiv e of its initial value\n",
      "(solid lines), even though the Lyapunov residual keeps getting sma ller (dashed lines). Benner et\n",
      "al. describe a more eﬃcient representation of the Riccati residual R(·) in relation to the Lyapunov\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 13\n",
      "50100150Number of columns zℓper Newton step.\n",
      "020406080Number of ADI iterations until convergence per Newton step.\n",
      "020406080Size of the linear systems comprising the ADI increment per N ewton step.\n",
      "1 2 3 4 5 6 7 8 9 10 11 1202,0004,0006,000\n",
      "Newton stepTotal number of linear solves up to the Newton step.\n",
      "old ADI new ADI\n",
      "Figure 1: Newton method (hybrid w/ line search) applied to solve ARE ( 28) arising from\n",
      "Example 5.3 . ADI shifts: heur(10 ,10,10). The ADI is started from a zero value ( )\n",
      "or with the previous Newton iterate ( ).\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 14Table 1: Total number of Newton iterations ℓmaxand ADI iterations ktotalperformed, the number of columns zℓmaxof the ﬁnal outer solution factor (its\n",
      "rank), as well as several run-time metrics to solve ARE ( 28) arising from Example 5.3 . All timings are in seconds. The ADI is started from a zero\n",
      "value (old) or with the previous Newton iterate (new). A dash (–) ind icates that the method did not converge. A speedup >1 indicates that our\n",
      "new ADI is faster.\n",
      "Newton method ADI shifts#ADI steps #Newton steps Rank tcompress tshifts tsolve ttotalSpeedup\n",
      "old new old new old new old new old new old new old new\n",
      "classical heur(10 ,10,10) 1273 756 15 15 146 151 10 .6 18.4 3.7 3.2 31.8 24.6 52.0 57.9 0.90\n",
      "classical heur(20 ,30,30) 740 514 15 15 147 151 5 .3 12.6 9.7 9.5 18.1 16.2 36.9 46.9 0.79\n",
      "classical proj(2 ,dec) 941 771 15 15 146 151 7 .5 24.0 0.6 0.8 23.0 28.3 36.6 67.4 0.54\n",
      "classical proj(2 ,heur) 748 805 15 15 148 151 5 .8 19.5 0.4 1.2 17.0 26.5 29.1 58.2 0.50\n",
      "classical proj(2 ,inc) 963 1525 15 15 145 151 8 .1 35.4 0.7 0.9 23.8 45.6 37.9 101.9 0.37\n",
      "classical w/ line search heur(10 ,10,10) 1175 676 12 12 146 151 9 .0 16.0 2.9 2.1 23.9 16.7 40.5 42.2 0.96\n",
      "classical w/ line search heur(20 ,30,30) 595 367 12 12 147 151 4 .2 8.3 7.6 6.9 14.0 12.2 30.2 35.4 0.85\n",
      "classical w/ line search proj(2 ,dec) 718 595 12 12 146 151 6 .2 19.2 0.4 0.6 16.3 23.3 28.1 55.7 0.51\n",
      "classical w/ line search proj(2 ,heur) 604 650 12 12 148 151 5 .0 16.9 0.6 0.7 13.9 20.4 24.2 49.1 0.49\n",
      "classical w/ line search proj(2 ,inc) 771 1302 12 12 145 151 7 .0 31.2 0.3 0.8 18.7 41.0 30.7 90.7 0.34\n",
      "inexact heur(10 ,10,10) 636 161 15 15 146 151 4 .4 7.8 3.7 3.6 13.5 6.3 26.2 22.7 1.15\n",
      "inexact heur(20 ,30,30) 419 185 15 15 147 151 3 .6 7.0 8.5 8.7 9.3 7.2 23.8 28.9 0.82\n",
      "inexact proj(2 ,dec) – 373 – 11 – 148 – 14 .1 – 0 .4 – 11 .8 – 33 .6 –\n",
      "inexact proj(2 ,heur) – – – – – – – – – – – – – – –\n",
      "inexact proj(2 ,inc) – – – – – – – – – – – – – – –\n",
      "inexact w/ line search heur(10 ,10,10) 589 142 12 12 146 151 4 .7 6.5 2.6 2.6 13.0 5.2 24.1 18.9 1.27\n",
      "inexact w/ line search heur(20 ,30,30) 404 162 12 12 147 151 3 .0 5.6 8.3 7.4 8.1 5.5 21.5 23.3 0.92\n",
      "inexact w/ line search proj(2 ,dec) – – – – – – – – – – – – – – –\n",
      "inexact w/ line search proj(2 ,heur) – – – – – – – – – – – – – – –\n",
      "inexact w/ line search proj(2 ,inc) – – – – – – – – – – – – – – –\n",
      "hybrid heur(10 ,10,10) 557 141 15 15 146 151 4 .1 6.6 3.7 2.6 12.2 4.9 23.7 18.4 1.29\n",
      "hybrid heur(20 ,30,30) 373 155 15 15 147 151 2 .2 6.4 10.3 8.8 7.4 5.4 22.8 27.7 0.82\n",
      "hybrid proj(2 ,dec) – 304 – 11 – 148 – 12 .2 – 0 .4 – 10 .6 – 29 .3 –\n",
      "hybrid proj(2 ,heur) – – – – – – – – – – – – – – –\n",
      "hybrid proj(2 ,inc) – – – – – – – – – – – – – – –\n",
      "hybrid w/ line search heur(10 ,10,10) 516 121 12 12 146 151 3 .6 5.0 2.1 2.1 9.6 3.6 18.3 15.7 1.17\n",
      "hybrid w/ line search heur(20 ,30,30) 348 132 12 12 147 151 2 .6 5.0 7.0 7.5 7.7 4.9 19.7 22.0 0.90\n",
      "hybrid w/ line search proj(2 ,dec) – – – – – – – – – – – – – – –\n",
      "hybrid w/ line search proj(2 ,heur) – – – – – – – – – – – – – – –\n",
      "hybrid w/ line search proj(2 ,inc) – – – – – – – – – – – – – – –\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 15\n",
      "0 50 100 150 200 250 300 350 400 450 50010−1210−810−4100\n",
      "Overall ADI stepRiccati residial; old ADI Riccati residial; new ADI\n",
      "Lyapunov residial; old ADI Lyapunov residial; new ADI\n",
      "Figure 2: Normalized Riccati residuals /bardblR(Xℓ+1,k)/bardbl//bardblR(0)/bardblfollowing the naive formula ( 32), and\n",
      "normalized Lyapunov residuals /bardblLℓ(Xℓ+1,k)/bardbl//bardblLℓ(0)/bardblfollowing Algorithm 3 , over the\n",
      "course of all ADI iterations kduring all Newton steps ℓ. Newton method: hybrid w/ line\n",
      "search. ADI shifts: heur(10 ,10,10). The ADI is started from a zero value (old) or with\n",
      "the previous Newton iterate (new).\n",
      "residualLℓ(·) and the change in the thin rectangular matrix BTXℓE∈Rm×n[7, Equation 5.2b].\n",
      "This representation allows to monitor the outer Riccati residual in t he inner ADI iteration, which\n",
      "we plan to add to our implementation in the future. Then the ADI can s top early whenever a\n",
      "suﬃcient decrease condition for the Newton step is fulﬁlled.\n",
      "We recommend to investigate the cause of the aforementioned sta gnation of the Riccati residual.\n",
      "Furthermore, a hybrid ADI approachshould be studied, that switc hes from the zero initial value to\n",
      "the non-zero one, once the hybrid Newton criterion ( 34c) resolves to the classical condition ( 34a).\n",
      "5.2. Diﬀerential Riccati Equation\n",
      "We apply a ﬁrst-order Rosenbrock scheme, the implicit Euler method , to the diﬀerential Riccati\n",
      "equation (DRE)\n",
      "ET˙XE=R(X) :=CTC+ATXE+ETXA−ETXBBTXE, ETX(t0)E=CTC,(35)\n",
      "where, again,\n",
      "E,A∈Rn×n, B∈Rn×m, C∈Rq×n, (36)\n",
      "andm,q≪n. AsCTCandBBTare positive semi-deﬁnite, equation ( 35) has a unique solution;\n",
      "see, e.g., [ 1, Theorem 4.1.6]. Motivated by Stillfjord [ 43] and following Lang, Mena, and Saak [ 31],\n",
      "we factorize the solution according to Xℓ=ZℓYℓZT\n",
      "ℓ≈X(t0+ℓτ) with\n",
      "Zℓ∈Rn×zℓ, Yℓ∈Rzℓ×zℓ, (37)\n",
      "wherezℓ≪n. Thus, every Rosenbrock step reads\n",
      "Lℓ(Xℓ+1) :=GℓSℓGT\n",
      "ℓ+AT\n",
      "ℓXℓ+1E+ETXℓ+1Aℓ= 0 (38)\n",
      "where\n",
      "Aℓ=A−1\n",
      "2τE−BBTXℓE∈Rn×n\n",
      "Gℓ=/bracketleftbig\n",
      "CTETZℓ/bracketrightbig\n",
      "∈Rn×(q+zℓ)\n",
      "Sℓ=/bracketleftbiggI\n",
      "YℓZT\n",
      "ℓBBTZℓYℓ+1\n",
      "τYℓ/bracketrightbigg\n",
      "∈R(q+zℓ)×(q+zℓ).(39)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 16\n",
      "Note, again, that Aℓhas the structure of a sparse matrix updated by a low-rank matrix prod-\n",
      "uct. This time, however, the inner dimension of the right-hand side GℓSℓGT\n",
      "ℓ, and therefore the\n",
      "corresponding Lyapunov residual Lℓ(Xℓ+1,k) both depend on the rank of the current Rosenbrock\n",
      "iterateXℓ. More precisely, the rank is at most ( q+zℓ)+2zℓ; see formula ( 17) withg=q+zℓand\n",
      "z=zℓ. Again, we do not yet utilize the common ETZℓin the outer low-rank factor, which would\n",
      "allow for a factorization having inner dimension q+2zℓ< q+3zℓand, thus, reduced compression\n",
      "times.\n",
      "Example 5.4. We apply the procedure described above to the Steel Proﬁle be nchmark [ 16,33],\n",
      "seeExample 5.3 . The time span is [t0,tf] = [0,4500], which we discretize in ℓmax= 45or\n",
      "450equidistant segments. That is, τ= 100or10. The convergence criterion (24)is based on\n",
      "reltolADI= 10−10;\n",
      "Table 2gives an overview on the number of ADI iterations required to solve t he DRE ( 35)\n",
      "arising from Example 5.4 . The timings are as described for Table 1. Refer to the beginning of this\n",
      "section for an explanation on the shift strategies chosen. Changin g the initial ADI guess from the\n",
      "zero matrix to the previous Rosenbrock iterate Xℓ−1always reduced the overall number of ADI\n",
      "iterations. In contrast to the previous section, the run-time is alw ays dominated by tcompress. This\n",
      "motivates, again, to improve the implementation of the low-rank colu mn compression.\n",
      "For this application, both ADIs are susceptible to the order of the s hifts. Focusing on the\n",
      "projection shifts for 450 Rosenbrock steps, the number of ADI it erations varies by more than 6 ×\n",
      "by merely changing the order of the shifts (old: 54657vs 8247, new : 9693 vs 1306). In terms of the\n",
      "number of iterations, the old ADI performs best for proj(2 ,heur) shifts and appears to degenerate\n",
      "for proj(2 ,dec) shifts. Meanwhile, the new ADI performs best for this order; taking less than 3\n",
      "steps on average; and mediocre for proj(2 ,heur) shifts.\n",
      "Figure 3 shows some more detail for one of the conﬁgurations of the table; the general shape is\n",
      "the same for all conﬁgurations. The DRE ( 35) is very stiﬀ during early Rosenbrock steps ℓ∈N.\n",
      "Once the integrator reaches a more transient regime for large-en oughℓ, using the non-zero initial\n",
      "ADI value reduces the number of ADI steps drastically; as expecte d. Surprisingly, however, the\n",
      "number of columns comprising the linear systems to compute the ADI increments ( 21) decreases\n",
      "as well. Apparently, the previous Rosenbrock iterate Xℓcontains enough information to cause the\n",
      "Lyapunov residual Lℓ(Xℓ) to vanish in many directions of the corresponding subspace. Over all,\n",
      "the new ADI has to solve fewer andcheaper linear systems. Consequently, the ﬁner the temporal\n",
      "resolution, the larger the expected speedup of the new ADI.5This notion is conﬁrmed by Table 2.\n",
      "When increasing the number of Rosenbrock steps by 10 ×, the total number of iterations and run-\n",
      "time of the new ADI only increase by roughly 2 .5 to 5×and 2 to 6×, respectively, depending on the\n",
      "shifts. Meanwhile, the total number of iterations and run-time of t he old ADI increase by roughly\n",
      "6 to 10×and 7.5 to 12×, respectively, depending on the shifts. Comparing the best shifts for each\n",
      "of the ADIs applied over 450 Rosenbrock steps, we observe a 6 ×reduction in ADI steps (8247 vs\n",
      "1306) and an 8×reduction in run-time (2484 .7s vs 313 .2s) in favor of our new ADI.\n",
      "Note that, although prescribed, the order of the heuristic shifts does not matter that much. The\n",
      "heuristic strategies compute only few (here: 10 or 20) shifts at on ce. Once all of them have been\n",
      "used, the iterates and residuals coincide; see Proposition 2.4 . The projection strategies, however,\n",
      "compute twice the inner dimension of the Lyapunov residual many at once (here: approx. 80 to\n",
      "250). For the vast majority of Rosenbrock steps, the ADI does c onverge after only a subset of\n",
      "these shifts has been used; that is, Proposition 2.4 does not apply. Further research is needed to\n",
      "understand the eﬀect of the shift order in such a scenario, and ho w to select the optimal shift order\n",
      "(and subset of shifts).\n",
      "6. Conclusion\n",
      "We introduced the notion of fully commuting splitting schemes to solve arbitrary linear systems,\n",
      "and derived the ADI method in that context. This allowed us to exten d the low-rank Lyapunov\n",
      "5Adaptive time stepping may reduce this advantage of our new A DI, as regions allowing for large time steps are\n",
      "the ones that would beneﬁt most from our initial values. Ther efore, as a stopgap speciﬁcally for Example 5.4 ,\n",
      "we select temporal resolutions that are rather coarse from a n engineer’s perspective.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 17\n",
      "100120140160Number of columns zℓper Rosenbrock step.\n",
      "01020Number of ADI iterations until convergence per Rosenbrock s tep.\n",
      "050100150Size of the linear systems comprising the ADI increment per R osenbrock step.\n",
      "1 50 100 150 200 250 300 350 400 45005·1051·106\n",
      "Rosenbrock stepTotal number of linear solves up to the Rosenbrock step.\n",
      "old ADI new ADI\n",
      "Figure 3: Rosenbrock method applied to solve DRE ( 35) arising from Example 5.4 . ADI shifts:\n",
      "heur(20,30,30). Rosenbrock step size τ= 10. The ADI is started from a zero value\n",
      "() or with the previous Rosenbrock iterate ( ).\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 18Table 2: Total number of ADI iterations ktotalperformed, the maximum number of columns max ℓzℓof the outer solution factor (maximum rank), as well\n",
      "as several run-time metrics to solve the DRE ( 35) arising from Example 5.4 . All timings are in seconds. The ADI is started from a zero value\n",
      "(old) or with the previous Rosenbrock iterate (new). A speedup >1 indicates that our new ADI is faster.\n",
      "#Rosenbrock\n",
      "stepsADI shifts#ADI steps Rank tcompress tshifts tsolve ttotalSpeedup\n",
      "old new old new old new old new old new old new\n",
      "45 heur(10 ,10,10) 1395 671 145 152 211 .8 41.2 7.6 7.6 53.5 18.8 314 .7 89.5 3.52\n",
      "45 heur(20 ,30,30) 1170 683 144 152 177 .8 43.4 24.3 24.1 44.7 19.0 282 .5 109.9 2.57\n",
      "45 proj(2 ,dec) 5685 550 144 152 971 .1 72.7 3.7 2.1 222.5 19.3 1357 .7 119.6 11.35\n",
      "45 proj(2 ,heur) 1266 821 145 152 201 .0 49.3 3.9 1.6 49.9 22.2 293 .7 97.3 3.02\n",
      "45 proj(2 ,inc) 4247 2172 142 152 670 .3 181.8 3.7 1.7 164.4 64.1 958 .7 296.0 3.24\n",
      "450 heur(10 ,10,10) 9450 3473 144 155 1572 .3 127.9 172.5 133.8 562.4 93.3 2742 .8 536.7 5.11\n",
      "450 heur(20 ,30,30) 9000 3392 144 155 1626 .2 139.6 243.6 285.9 487.2 93.8 2849 .3 706.9 4.03\n",
      "450 proj(2 ,dec) 54657 1306 141 154 10727 .1 73.6 38.2 8.2 3525.8 54.0 16405 .3 313.2 52.38\n",
      "450 proj(2 ,heur) 8247 3739 144 152 1511 .3 129.8 38.6 10.1 538.5 119.0 2484 .7 469.9 5.29\n",
      "450 proj(2 ,inc) 25487 9693 144 151 4677 .9 396.3 37.3 12.4 1646.7 322.1 7401 .2 1037.6 7.13\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 19\n",
      "ADI for complex data to non-zero initial values. Furthermore, we g eneralized the permutation\n",
      "invariance of ADI iterates to arbitrary fully commuting splitting sche mes (Proposition 2.4 ), as well\n",
      "as the existence of a real-valued ADI double-step for complex-con jugated shifts to arbitrary linear\n",
      "systems ( Theorem 3.2 ).\n",
      "We applied the extended low-rank Lyapunov ADI to a Newton and a Ro senbrock method to\n",
      "solve an algebraic and a diﬀerential Riccati equation, respectively. For the Newton method we\n",
      "observed a 4×lower total number of ADI steps for heuristic Penzl shifts, but mo re expensive linear\n",
      "systems at every ADI step. Overall, for this application, our impleme ntation only showed a modest\n",
      "17% run-time improvement over the old ADI. For the Rosenbrock me thod, however, we observed\n",
      "a 2 to 6×lower total number of ADI steps, depending on the shifts, whose lin ear systems have\n",
      "fewer columns, resulting in an 8 ×speed-up in our implementation.\n",
      "Code and Data Availability\n",
      "The algorithms have been implemented using Julia [ 21] and are available at:\n",
      "DOI10.5281/zenodo.10650859\n",
      "The datasets analyzed in this paper are available at:\n",
      "Newton: DOI 10.5281/zenodo.10650872\n",
      "Rosenbrock: DOI 10.5281/zenodo.10651124\n",
      "Acknowledgments\n",
      "We would like to thank Daniel Szyld for pointing out the name nonstationary splitting scheme.\n",
      "We further thank Fan Wang and Martin K¨ ohler for their review of our codes and independent\n",
      "veriﬁcation of the reproducibility of the numerical experiments.\n",
      "A. Order of ADI shifts\n",
      "As we have observedin Section 5 , the low-rankLyapunovADI can be quite sensitive to the orderof\n",
      "its shifts. In this section, we give some intuition on why the projectio n shifts ordered by increasing\n",
      "real part, proj(2 ,inc), sometimes lead to large numbers of ADI iterations.\n",
      "Using the notation of Section 2 , the iteration map of the symmetry-preserving low-rank Lya-\n",
      "punov ADI, as derived in Section 4 , is given by\n",
      "Gk(U) := (M−1\n",
      "kNk)(U) =C(A,αk)UC(A,αk)H, (40)\n",
      "using the operator split ( 16),βk:=αk, and the Cayley transformation\n",
      "C(A,α) := (A+αI)−1(A−αI). (41)\n",
      "If applied to a symmetric low-rank factorization ZYZH, the iteration map eﬀectively only operates\n",
      "on the outer factors Z. Recall that a nonstationary splitting scheme converges iﬀ ρ(Gk···G0)→0\n",
      "ask→∞. A suﬃcient condition is thus\n",
      "ρ/parenleftbig\n",
      "C(A,αk)···C(A,α0)/parenrightbig\n",
      "→0 (42)\n",
      "ask→∞. As the spectral radius is sub-multiplicative, the upper bound\n",
      "ρ/parenleftbig\n",
      "C(A,αk)···C(A,α0)/parenrightbig\n",
      "≤ρ/parenleftbig\n",
      "C(A,αk)/parenrightbig\n",
      "···ρ/parenleftbig\n",
      "C(A,α0)/parenrightbig\n",
      "=: ˆρk (43)\n",
      "holds. It can be computed as follows. By, e.g., [ 30, Proposition 2.16], the spectral radius of such\n",
      "a Cayley transformation is given as\n",
      "ρ(C(A,α)) = max/braceleftbigg|λ−α|\n",
      "|λ+α|:λ∈Λ(A)/bracerightbigg\n",
      ". (44)\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 20\n",
      "−10−1−10−3−10−50.9940.9960.9981\n",
      "Eigenvalue λ∈Λ(A)Spectral radius ρ(C(A,λ))\n",
      "0 100 200 3000.70.80.91\n",
      "ADI step kUpper bound ˆ ρk\n",
      "increasing real part\n",
      "Penzl’s heuristic\n",
      "decreasing real part\n",
      "Figure 4: Spectral radius of Cayley transformations associated t o spectrum of A, and upper bound\n",
      "ˆρkon the norm of parts of the iteration map over the course of multiple ADI iterations k,\n",
      "for diﬀerent permutations of the spectrum Λ( A).\n",
      "If we chose the parameters {α0,...,α k}to be (a subset of) the spectrum Λ( A), it holds\n",
      "ρ(C(A,αk))≤1 for any k. Furthermore, every eigenvector vofAto the eigenvalue λlives in\n",
      "the null space of C(A,λ). Consequently, if the whole Λ( A) is chosen, the norm of the combined\n",
      "stepρ/parenleftbig\n",
      "C(A,αk)···C(A,α0)/parenrightbig\n",
      "will be zero. On the other hand, any individual ρ(C(A,αk))>0.\n",
      "That is, ˆ ρkis not a sharp upper bound.\n",
      "Figure 4 shows the aforementioned upper bound ˆ ρ0=ρ(C(A,α0)) and ˆρkfor a smaller conﬁgu-\n",
      "ration of the Steel Proﬁle [ 16,33] benchmark having matrix dimension n= 371. The corresponding\n",
      "(generalized) spectrum is contained in the negative half plane, and t he whole set is chosen as the\n",
      "parameter set{α0,...,α n−1}. These parameters may be ordered by increasing real part (similar\n",
      "to proj(2 ,inc)), by decreasing real part (similar to proj(2 ,dec)), or by Penzl’s heuristic (similar to\n",
      "proj(2,heur)); see page 9. Note that Penzl’s heuristic [ 36] chooses the ﬁrst shift α0to be the one\n",
      "minimizing ρ(C(A,·)) = ˆρ0, and continues greedily to select αkby minimizing\n",
      "k−1/productdisplay\n",
      "i=0|αk−αi|\n",
      "|αk+αi|(45)\n",
      "for given{α0,...,α k−1}.6Quantity ( 45) is related to ˆ ρk, but not the same.7Consequently, the\n",
      "heuristic is the only one for which the corresponding ˆ ρ0is visibly smaller than 1.\n",
      "Obviously, all upper bounds ˆ ρkcoincide for k=n−1, as the underlying product of spectral\n",
      "radii (43) is formed over the whole set of parameters. The decreasing orde r clearly yields a better a\n",
      "priori upper bound than the increasing order. Interestingly, the heuristic order starts out smallest,\n",
      "remains in between the other two orders for most iterations, but c omes out largest towards the last\n",
      "iterations. Thus, formostcases,weexpecttheproj(2 ,dec) shiftstorequiretheleastnumberofADI\n",
      "steps until convergence, followed by proj(2 ,heur) and proj(2 ,inc), in that order. Unfortunately,\n",
      "however, this intuition can only be conﬁrmed for the new ADI in Tables 1and2.\n",
      "References\n",
      "[1]H. Abou-Kandil, G. Freiling, V. Ionescu, and G. Jank ,Matrix Riccati Equations in\n",
      "Control and Systems Theory , Systems & Control: Foundations & Applications, Birkh¨ auser\n",
      "6The heuristic includes αk+1:=αkifαk∈C\\R. For the present example, however, this does not occur.\n",
      "7Note the lack of conjugation in the numerators. Furthermore , each factor containing αiis in general only a lower\n",
      "bound to ρ(C(A,αi)), which renders quantity ( 45) smaller than ˆ ρk−1.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 21\n",
      "Basel, Basel, 2003. DOI 10.1007/978-3-0348-8081-7 . Cited on page(s) 6,15.\n",
      "[2]A. C. Antoulas ,Approximation of Large-Scale Dynamical Systems , Society for Industrial\n",
      "and Applied Mathematics, 2005. DOI 10.1137/1.9780898718713 . Cited on page(s) 2.\n",
      "[3]A. C. Antoulas, D. C. Sorensen, and Y. Zhou ,On the Decay Rate of Hankel Sin-\n",
      "gular Values and Related Issues , Systems & Control Letters, 46 (2002), pp. 323–342. DOI\n",
      "10.1016/S0167-6911(02)00147-0 . Cited on page(s) 6.\n",
      "[4]B. Baran, P. Benner, and J. Saak ,Riccati Feedback Control of a Two-dimensional\n",
      "Two-phase Stefan Problem , e-print arXiv:2209.05476, arXiv, 2022. math.NA. DOI\n",
      "10.48550/arXiv.2209.05476 . Cited on page(s) 2.\n",
      "[5]B. Baran, P. Benner, J. Saak, and T. Stillfjord ,Numerical methods for closed-loop\n",
      "systems with non-autonomous data , e-print arXiv:2402.13656, arXiv, 2024. math.NA. DOI\n",
      "10.48550/arXiv.2402.13656 . Cited on page(s) 2.\n",
      "[6]P. Benner and Z. Bujanovi ´c,On the solution of large-scale algebraic Riccati equations\n",
      "by using low-dimensional invariant subspaces , Linear Algebra Appl., 488 (2016), pp. 430–459.\n",
      "DOI10.1016/j.laa.2015.09.027 . Cited on page(s) 10.\n",
      "[7]P. Benner, M. Heinkenschloss, J. Saak, and H. K. Weichelt ,An inexact low-rank\n",
      "Newton-ADI method for large-scale algebraic Riccati equat ions, Appl. Numer. Math., 108\n",
      "(2016), pp. 125–142. DOI 10.1016/j.apnum.2016.05.006 . Cited on page(s) 11,12,15.\n",
      "[8]P. Benner and P. K ¨urschner ,Computing Real Low-Rank Solutions of Sylvester Equa-\n",
      "tions by the Factored ADI Method , Computers & Mathematics with Applications, 67 (2014),\n",
      "pp. 1656–1672. DOI 10.1016/j.camwa.2014.03.004 . Cited on page(s) 6,9.\n",
      "[9]P. Benner, P. K ¨urschner, and J. Saak ,Real versions of low-rank ADI methods with\n",
      "complex shifts , Technical report MPIMD/12-11, Max Planck Institute Magdebur g, 2012.\n",
      "https://csc.mpi-magdeburg.mpg.de/preprints/2012/11/ . Cited on page(s) 2.\n",
      "[10] ,A Reformulated Low-Rank ADI Iteration with Explicit Residu al Factors , PAMM, 13\n",
      "(2013), pp. 585–586. DOI 10.1002/pamm.201310273 . Cited on page(s) 2.\n",
      "[11] ,An improved numerical method for balanced truncation for sy mmetric second-order\n",
      "systems, Mathematical and Computer Modelling of Dynamical Systems, 19 (2 013), pp. 593–\n",
      "615. DOI 10.1080/13873954.2013.794363 . Cited on page(s) 2,7.\n",
      "[12] ,Eﬃcient Handling of Complex Shift Parameters in the Low-Ran k Cholesky Factor ADI\n",
      "Method, Numerical Algorithms, 62 (2013), pp. 225–251. DOI 10.1007/s11075-012-9569-7 .\n",
      "Cited on page(s) 2,6,7.\n",
      "[13] ,Self-Generating and Eﬃcient Shift Parameters in ADI Method s for Large Lya-\n",
      "punov and Sylvester Equations , Electron. Trans. Numer. Anal., 43 (2014), pp. 142–162.\n",
      "http://etna.mcs.kent.edu/volumes/2011-2020/vol43/ab stract.php?vol=43&pages=142-162 .\n",
      "Cited on page(s) 7,9.\n",
      "[14]P. Benner, J.-R. Li, and T. Penzl ,Numerical solution of large-scale Lyapunov equations,\n",
      "Riccati equations, and linear-quadratic optimal control p roblems, Numerical Linear Algebra\n",
      "with Applications, 15 (2008), pp. 755–777. DOI 10.1002/nla.622 . Cited on page(s) 2,6,7,8,\n",
      "10,11.\n",
      "[15]P. Benner, R.-C. Li, and N. Truhar ,On the ADI method for Sylvester equations ,\n",
      "Journal of Computational and Applied Mathematics, 233 (2009), p p. 1035–1045. DOI\n",
      "10.1016/j.cam.2009.08.108 . Cited on page(s) 2,6,8.\n",
      "[16]P. Benner and J. Saak ,Linear-Quadratic Regulator Design for Optimal Cooling of S teel\n",
      "Proﬁles, techreport SFB393/05-05, Sonderforschungsbereich 393 Parallele Numerische Sim-\n",
      "ulation f¨ ur Physik und Kontinuumsmechanik , TU Chemnitz, D-09107 Chemnitz (Germany),\n",
      "2005.http://nbn-resolving.de/urn:nbn:de:swb:ch1-20060159 7. Cited on page(s) 11,\n",
      "16,20.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 22\n",
      "[17] ,Numerical Solution of Large and Sparse Continuous Time Alge braic Matrix Riccati and\n",
      "Lyapunov Equations: A State of the Art Survey , GAMM-Mitteilungen, 36 (2013), pp. 32–52.\n",
      "DOI10.1002/gamm.201310003 . Cited on page(s) 2.\n",
      "[18]C. Bertram and H. Faßbender ,Riccati ADI: Existence, Uniqueness and New Iterative\n",
      "Methods, techreport arXiv:2004.11212, 2020. http://arxiv.org/abs/2004.11212 . Cited on\n",
      "page(s)2.\n",
      "[19] ,A Link Between Gramian-Based Model Order Reduction and Mome nt Matching , in\n",
      "Model Reduction of Complex Dynamical Systems, P. Benner, T. Bre iten, H. Faßbender,\n",
      "M. Hinze, T. Stykel, and R. Zimmermann, eds., vol. 171, Springer Int ernational Publishing,\n",
      "Cham, 2021, pp. 119–139. DOI 10.1007/978-3-030-72983-7˙6 . Cited on page(s) 2.\n",
      "[20] ,A Quadrature Framework for Solving Lyapunov and Sylvester E quations, Linear Alge-\n",
      "bra and its Applications, 622 (2021), pp. 66–103. DOI 10.1016/j.laa.2021.03.029 . Cited on\n",
      "page(s)2.\n",
      "[21]J. Bezanson, A. Edelman, S. Karpinski, and V. B. Shah ,Julia: A Fresh Approach to\n",
      "Numerical Computing , SIAM Review, 59 (2017), pp. 65–98. DOI 10.1137/141000671 . Cited\n",
      "on page(s) 19.\n",
      "[22]R. S. Dembo, S. C. Eisenstat, and T. Steihaug ,Inexact Newton Methods , SIAM Journal\n",
      "on Numerical Analysis, 19 (1982), pp. 400–408. DOI 10.1137/0719025 . Cited on page(s) 11.\n",
      "[23]G. H. Golub and C. F. van Loan ,Matrix Computations , Johns Hopkins University Press,\n",
      "4 ed., 2013. Cited on page(s) 3,8,10.\n",
      "[24]L. Grasedyck ,Existence of a Low Rank or H-matrix Approximant to the Solution of a\n",
      "Sylvester Equation , Numerical Linear Algebra with Applications, 11 (2004), pp. 371–38 9.\n",
      "DOI10.1002/nla.366 . Cited on page(s) 6.\n",
      "[25]S. Gugercin and J.-R. Li ,Smith-Type Methods for Balanced Truncation of Large Sparse\n",
      "Systems, in Dimension Reduction of Large-Scale Systems, P. Benner, D. C. S orensen, and\n",
      "V. Mehrmann, eds., vol. 45, Springer-Verlag, Berlin/Heidelberg, 20 05, pp. 49–82. DOI\n",
      "10.1007/3-540-27909-1˙2 . Cited on page(s) 2.\n",
      "[26]W. Hackbusch ,Iterative Solution of Large Sparse Systems of Equations , vol. 95 of Applied\n",
      "Mathematical Sciences, 2016. DOI 10.1007/978-3-319-28483-5 . Cited on page(s) 3.\n",
      "[27]R. A. Horn and C. R. Johnson ,Topics in Matrix Analysis , Cambridge University Press,\n",
      "1 ed., 1991. DOI 10.1017/CBO9780511840371 . Cited on page(s) 6.\n",
      "[28]I. M. Jaimoukha and E. M. Kasenally ,Krylov Subspace Methods for Solving Large\n",
      "Lyapunov Equations , SIAM Journal on Numerical Analysis, 31 (1994), pp. 227–251. DO I\n",
      "10.1137/0731012 . Cited on page(s) 2.\n",
      "[29]D. Kressner, K. Lund, S. Massei, and D. Palitta ,Compress-and-restart Block Krylov\n",
      "Subspace Methods for Sylvester Matrix Equations , Numerical Linear Algebra with Applica-\n",
      "tions, 28 (2021), p. e2339. DOI 10.1002/nla.2339 . Cited on page(s) 2.\n",
      "[30]P. K¨urschner ,Eﬃcient low-rank solution of large-scale matrix equa-\n",
      "tions, Ph.D. thesis, Otto-von-Guericke-Universit¨ at Magdeburg, 201 6.\n",
      "https://hdl.handle.net/11858/00-001M-0000-0029-CE18 -2. Cited on page(s) 2,9,\n",
      "19.\n",
      "[31]N. Lang, H. Mena, and J. Saak ,On the beneﬁts of the LDLTfactorization for large-\n",
      "scale diﬀerential matrix equation solvers , Linear Algebra and its Applications, 480 (2015),\n",
      "pp. 44–71. DOI 10.1016/j.laa.2015.04.006 . Cited on page(s) 2,6,7,10,15.\n",
      "[32]J.-R. Li and J. White ,Low rank solution of Lyapunov equations , SIAM Journal on Matrix\n",
      "Analysis and Applications, 24 (2002), pp. 260–280. DOI 10.1137/S0895479801384937 . Cited\n",
      "on page(s) 2,4,6,8.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n",
      "J. Schulze, J. Saak 23\n",
      "[33]Oberwolfach Benchmark Collection ,Steel Proﬁle . hosted at MORwiki – Model Order\n",
      "Reduction Wiki, 2005. http://modelreduction.org/index.php/Steel_Profile . Cited on\n",
      "page(s)11,16,20.\n",
      "[34]D. Palitta and V. Simoncini ,Computationally Enhanced Projection Methods for Sym-\n",
      "metric Sylvester and Lyapunov Matrix Equations , Journal of Computational and Applied\n",
      "Mathematics, 330 (2018), pp. 648–659. DOI 10.1016/j.cam.2017.08.011 . Cited on page(s) 2.\n",
      "[35]D. W. Peaceman and H. H. Rachford, Jr ,The numerical solution of parabolic and\n",
      "elliptic diﬀerential equations , Journal of the Society for industrial and Applied Mathematics,\n",
      "3 (1955), pp. 28–41. DOI 10.1137/0103003 . Cited on page(s) 4.\n",
      "[36]T. Penzl ,A Cyclic Low-Rank Smith Method for Large Sparse Lyapunov Equ ations, SIAM\n",
      "Journal on Scientiﬁc Computing, 21 (1999), pp. 1401–1418. DOI 10.1137/S1064827598347666 .\n",
      "Cited on page(s) 2,7,8,9,20.\n",
      "[37] ,Eigenvalue Decay Bounds for Solutions of Lyapunov Equation s: The Symmetric Case ,\n",
      "Systems & Control Letters, 40 (2000), pp. 139–144. DOI 10.1016/S0167-6911(00)00010-4 .\n",
      "Cited on page(s) 6.\n",
      "[38]J. Saak ,Eﬃcient Numerical Solution of Large Scale Algebraic Ma-\n",
      "trix Equations in PDE Control and Model Order Reduction , 2009.\n",
      "http://nbn-resolving.de/urn:nbn:de:bsz:ch1-20090164 2. Cited on page(s) 6,9.\n",
      "[39]J. Sabino ,Solution of Large-Scale Lyapunov Equations via the Block Mo diﬁed Smith Method ,\n",
      "Ph.D. thesis, Rice University, 2007. https://hdl.handle.net/1911/20641 . Cited on\n",
      "page(s)6.\n",
      "[40]J. Schulze ,A Low-Rank Parareal Solver for Diﬀerential Riccati Equatio ns Written in Julia ,\n",
      "2022. DOI 10.5281/zenodo.7843198 . Cited on page(s) 2,3,4.\n",
      "[41]V. Simoncini ,A New Iterative Method for Solving Large-Scale Lyapunov Mat rix Equations ,\n",
      "SIAM Journal on Scientiﬁc Computing, 29 (2007), pp. 1268–1288. DOI10.1137/06066120X .\n",
      "Cited on page(s) 2.\n",
      "[42] ,Computational Methods for Linear Matrix Equations , SIAMReview, 58(2016),pp.377–\n",
      "441. DOI 10.1137/130912839 . Cited on page(s) 2.\n",
      "[43]T. Stillfjord ,Singular Value Decay of Operator-Valued Diﬀerential Lyapu nov and Riccati\n",
      "Equations , SIAM J. Control Optim., 56 (2018), pp. 3598–3618. DOI 10.1137/18M1178815 .\n",
      "Cited on page(s) 15.\n",
      "[44]H. T. Stoppels and L. Nyman ,ArnoldiMethod.jl: Arnoldi Method with Krylov-Schur\n",
      "restart, natively in Julia .https://github.com/JuliaLinearAlgebra/ArnoldiMethod .jl.\n",
      "Cited on page(s) 9.\n",
      "[45]N. Truhar and K. Veseli ´c,Bounds on the Trace of a Solution to the Lyapunov Equation\n",
      "with a General Stable Matrix , Systems & Control Letters, 56 (2007), pp. 493–503. DOI\n",
      "10.1016/j.sysconle.2007.02.003 . Cited on page(s) 6.\n",
      "[46]E. Wachspress ,The ADI Model Problem , Springer New York, New York, NY, 2013. DOI\n",
      "10.1007/978-1-4614-5122-8 . Cited on page(s) 2.\n",
      "[47]T. Wolf and H. K. F. Panzer ,The ADI Iteration for Lyapunov Equations Implicitly\n",
      "Performs H2 Pseudo-Optimal Model Order Reduction , International Journal of Control, 89\n",
      "(2016), pp. 481–493. DOI 10.1080/00207179.2015.1081985 . Cited on page(s) 2,7.\n",
      "Preprint (Max Planck Institute for Dynamics of Complex Tech nical Systems, Magdeburg). 2025-01-24\n"
     ]
    }
   ],
   "source": [
    "for page in pdf.pages:\n",
    "    print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86efbf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = [url.split('/')[-1] for url in pdf_urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be604fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2406.13477v3',\n",
       " '2309.00979v1',\n",
       " '2310.13661v1',\n",
       " '1001.2876v2',\n",
       " '1401.5182v2',\n",
       " '1406.4251v2',\n",
       " '1710.09143v1',\n",
       " '2501.05715v1',\n",
       " '1912.05412v1',\n",
       " '1207.5909v1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab37cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_html_links = [f\"https://arxiv.org/html/{paper_id}\" for paper_id in paper_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75e42ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://arxiv.org/html/2406.13477v3',\n",
       " 'https://arxiv.org/html/2309.00979v1',\n",
       " 'https://arxiv.org/html/2310.13661v1',\n",
       " 'https://arxiv.org/html/1001.2876v2',\n",
       " 'https://arxiv.org/html/1401.5182v2',\n",
       " 'https://arxiv.org/html/1406.4251v2',\n",
       " 'https://arxiv.org/html/1710.09143v1',\n",
       " 'https://arxiv.org/html/2501.05715v1',\n",
       " 'https://arxiv.org/html/1912.05412v1',\n",
       " 'https://arxiv.org/html/1207.5909v1']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_html_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f823c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "link = paper_html_links[2]\n",
    "response = requests.get(link)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1eeec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Introduction\n",
      "\n",
      "2 How are Current ADI Datasets Built?\n",
      "\n",
      "3 Maximal Accuracy of Single-label ADI Datasets\n",
      "\n",
      "4 Estimating the Maximal Accuracy of Datasets\n",
      "\n",
      "5 Proposal for Framing the ADI Task\n",
      "\n",
      "6 Conclusion\n",
      "Limitations\n",
      "Acknowledgments\n",
      "References\n",
      "\n",
      "Appendix A Detailed Dialect Coverage and Model Performance Report\n",
      "\n",
      "Appendix B The Error Analysis Survey\n"
     ]
    }
   ],
   "source": [
    "for paragraph in soup.find_all('h2'):\n",
    "    print(paragraph.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e05af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06819eaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
